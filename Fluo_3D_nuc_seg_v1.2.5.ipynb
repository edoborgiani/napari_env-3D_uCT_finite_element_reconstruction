{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af325be-1697-46f9-ad1f-39f2451d9614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install aicsimageio[nd2]\n",
    "!pip install nd2reader\n",
    "!pip install xlsxwriter\n",
    "!pip install reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1262a-3ccc-4c94-8f6e-8a5784ced14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OpenCV version\n",
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e2ef9-43a3-43d2-a0cb-17fe199b14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import napari\n",
    "from napari.settings import get_settings\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.lines import Line2D\n",
    "import SimpleITK as sitk\n",
    "import skimage\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import label, zoom, binary_dilation, generate_binary_structure\n",
    "from skimage.segmentation import watershed, relabel_sequential\n",
    "from itertools import combinations\n",
    "from vispy.color import Colormap\n",
    "from matplotlib.colors import to_rgb\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.models import StarDist2D\n",
    "from collections import defaultdict\n",
    "from aicsimageio import AICSImage\n",
    "from nd2reader import ND2Reader\n",
    "import meshlib.mrmeshpy as mr\n",
    "import meshlib.mrmeshnumpy as mrn\n",
    "from IPython.display import clear_output\n",
    "import meshio\n",
    "import statistics as st\n",
    "import tetgen\n",
    "\n",
    "from skimage import filters, morphology\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import ball\n",
    "from skimage.filters import threshold_otsu, threshold_niblack, threshold_sauvola\n",
    "from skimage.measure import find_contours, regionprops\n",
    "from skimage.draw import line as draw_line  # For line drawing\n",
    "\n",
    "import xlsxwriter\n",
    "from scipy.stats import gaussian_kde\n",
    "from PIL import Image as PILImage\n",
    "from reportlab.platypus import Image as RLImage\n",
    "from reportlab.platypus import (\n",
    "    SimpleDocTemplate, Image, Paragraph, Spacer, Table, TableStyle, PageBreak\n",
    ")\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib import colors\n",
    "\n",
    "from collections import defaultdict\n",
    "from skimage.segmentation import relabel_sequential\n",
    "\n",
    "# Enable interactive mode for napari in Jupyter\n",
    "settings = get_settings()\n",
    "settings.application.ipy_interactive = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a39a6-25b4-497e-bfe1-5250ba3ad7bc",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f0f80-eaef-49a8-b5b7-f772bcfb4f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing and utility functions\n",
    "\n",
    "def gamma_trans(im_in, gamma):\n",
    "    \"\"\"Apply gamma correction to an image.\"\"\"\n",
    "    val_c = 255.0 / (np.max(im_in)**gamma)\n",
    "    return (val_c * (im_in**gamma)).copy()\n",
    "\n",
    "def napari_gamma(image, gamma):\n",
    "    \"\"\"\n",
    "    Apply gamma correction in the same way as Napari.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        2D or 3D image, integer or float.\n",
    "        If integer, assumed to be full-range (uint8, uint16).\n",
    "    gamma : float\n",
    "        Same gamma exponent used in Napari.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corrected : numpy.ndarray\n",
    "        Gamma-corrected image with the same dtype as input.\n",
    "    \"\"\"\n",
    "\n",
    "    # preserve original dtype to restore at the end\n",
    "    dtype = image.dtype\n",
    "\n",
    "    # convert to float in [0,1]\n",
    "    img = image.astype(np.float32)\n",
    "    img /= img.max() if img.max() != 0 else 1.0\n",
    "\n",
    "    # apply gamma\n",
    "    img = img ** gamma\n",
    "\n",
    "    # rescale back to original dtype range\n",
    "    if np.issubdtype(dtype, np.integer):\n",
    "        info = np.iinfo(dtype)\n",
    "        img = np.clip(img * info.max, 0, info.max).astype(dtype)\n",
    "    else:\n",
    "        img = img.astype(dtype)\n",
    "\n",
    "    return img\n",
    "\n",
    "def contr_limit(im_in, c_min=None, c_max=None):\n",
    "    \"\"\"\n",
    "    Stretch the contrast of the input image to the 0–255 range.\n",
    "    \n",
    "    Parameters:\n",
    "    - im_in: Input image (NumPy array).\n",
    "    - c_min: Minimum intensity to map to 0. If None, uses im_in.min().\n",
    "    - c_max: Maximum intensity to map to 255. If None, uses im_in.max().\n",
    "    \n",
    "    Returns:\n",
    "    - Contrast-stretched image (uint8).\n",
    "    \"\"\"\n",
    "    im_in = im_in.astype(float)\n",
    "    \n",
    "    if c_min is None:\n",
    "        c_min = im_in.min()\n",
    "    if c_max is None:\n",
    "        c_max = im_in.max()\n",
    "    \n",
    "    if c_max == c_min:\n",
    "        return np.zeros_like(im_in, dtype=np.uint8)  # avoid division by zero\n",
    "\n",
    "    alpha = 255.0 / (c_max - c_min)\n",
    "    beta = -c_min * alpha\n",
    "\n",
    "    im_out = alpha * im_in + beta\n",
    "    #return np.clip(im_out, 0, 255).astype(np.uint8)\n",
    "    return (im_out).astype(np.uint8)\n",
    "\n",
    "def contr_stretch(im_in, c_min=None, c_max=None):\n",
    "    \"\"\"\n",
    "    Mimic Fiji's Brightness/Contrast adjustment.\n",
    "    Values below min_input become 0.\n",
    "    Values above max_input become 255.\n",
    "    Values in between are linearly scaled to 0–255.\n",
    "    \n",
    "    Parameters:\n",
    "    - im_in: Input image (NumPy array).\n",
    "    - min_input: Input value to be mapped to 0.\n",
    "    - max_input: Input value to be mapped to 255.\n",
    "    \n",
    "    Returns:\n",
    "    - Adjusted image (uint8).\n",
    "    \"\"\"\n",
    "    im_in = im_in.astype(float)\n",
    "\n",
    "    if c_min is None:\n",
    "        c_min = im_in.min()\n",
    "    if c_max is None:\n",
    "        c_max = im_in.max()\n",
    "    \n",
    "    if c_max == c_min:\n",
    "        return np.zeros_like(im_in, dtype=np.uint8)  # avoid division by zero\n",
    "\n",
    "    # Normalize: subtract min and divide by (max - min)\n",
    "    norm = (im_in - c_min) / (c_max - c_min)\n",
    "    \n",
    "    # Clip to [0, 1] so values outside range are fixed to 0 or 1\n",
    "    norm = np.clip(norm, 0, 1)\n",
    "    \n",
    "    return (norm * 255).astype(np.uint8)\n",
    "\n",
    "def napari_contrast_gamma_uint8(image, contrast_limits, gamma):\n",
    "    \"\"\"\n",
    "    Apply Napari-style contrast limits + gamma correction,\n",
    "    and return the resulting image as uint8.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        Input image (any dtype).\n",
    "    contrast_limits : tuple (clim_min, clim_max)\n",
    "        Same values you see in Napari GUI.\n",
    "    gamma : float\n",
    "        Gamma value from Napari GUI.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out_uint8 : np.ndarray (uint8)\n",
    "        Image transformed exactly like Napari display,\n",
    "        then mapped to 0–255.\n",
    "    \"\"\"\n",
    "\n",
    "    clim_min, clim_max = contrast_limits\n",
    "\n",
    "    # Convert to float\n",
    "    img = image.astype(np.float32)\n",
    "\n",
    "    # Napari contrast normalization\n",
    "    img = (img - clim_min) / (clim_max - clim_min)\n",
    "    img = np.clip(img, 0.0, 1.0)\n",
    "\n",
    "    # Napari gamma\n",
    "    img = img ** gamma\n",
    "\n",
    "    # Convert display range [0,1] → uint8 [0,255]\n",
    "    out_uint8 = (img * 255).round().astype(np.uint8)\n",
    "\n",
    "    return out_uint8\n",
    "\n",
    "def hist_plot(im_in, stain_complete_df, thresh=0):\n",
    "    \"\"\"Plot histogram and CDF for each channel.\"\"\"\n",
    "    fig, axs = plt.subplots(1, im_in.shape[3], figsize=(15, 2))\n",
    "    for c in range(im_in.shape[3]):\n",
    "        hist, _ = np.histogram(im_in[:, :, :, c].flatten(), 256, [0, 256])\n",
    "        cdf = hist.cumsum()\n",
    "        cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "        color = stain_complete_df.loc[stain_complete_df.index[c], 'Color']\n",
    "        axs[c].plot(cdf_normalized, color='b')\n",
    "        axs[c].hist(im_in[:, :, :, c].flatten(), 256, [0, 256], color=color if color != 'WHITE' else 'GRAY')\n",
    "        axs[c].set_xlim([0, 256])\n",
    "        axs[c].legend(('cdf', 'histogram'), loc='upper left')\n",
    "        if thresh > 0:\n",
    "            axs[c].plot([thresh, thresh], [0, cdf_normalized.max()], color='g')\n",
    "        axs[c].set_title(stain_complete_df.index[c])\n",
    "        axs[c].set_yscale('log')\n",
    "\n",
    "def truncate_cell(val, width=15):\n",
    "    \"\"\"Truncate long values for display in tables.\"\"\"\n",
    "    val_str = str(val)\n",
    "    return val_str if len(val_str) <= width else val_str[:width-3] + \"...\"\n",
    "\n",
    "def merge_touching_labels(\n",
    "    label_matrix,\n",
    "    contact_abs_min=20,\n",
    "    contact_rel_min=0.05,\n",
    "    connectivity=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Merge touching labels in a 3D label matrix using union-find, but only when\n",
    "    the shared boundary between two labels is large enough.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label_matrix : ndarray, int\n",
    "        3D label image (0 = background).\n",
    "    contact_abs_min : int\n",
    "        Minimum number of boundary voxels two labels must share to be eligible\n",
    "        for merging.\n",
    "    contact_rel_min : float\n",
    "        Minimum relative contact (shared boundary / min(volume_i, volume_j))\n",
    "        to be eligible for merging.\n",
    "    connectivity : {1, 2, 3}\n",
    "        Neighborhood connectivity used to define touching (1=6-neighborhood,\n",
    "        2≈18, 3=26-neighborhood in 3D).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    merged : ndarray, int\n",
    "        Relabeled image with selected touching labels merged.\n",
    "    \"\"\"\n",
    "    if label_matrix.max() == 0:\n",
    "        return label_matrix.copy()\n",
    "\n",
    "    # Precompute volumes of each label\n",
    "    labels, counts = np.unique(label_matrix, return_counts=True)\n",
    "    volumes = dict(zip(labels.tolist(), counts.tolist()))\n",
    "    volumes.pop(0, None)  # remove background\n",
    "\n",
    "    # Connectivity: generate neighbor offsets\n",
    "    offsets = []\n",
    "    for dz in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            for dx in [-1, 0, 1]:\n",
    "                if dz == dy == dx == 0:\n",
    "                    continue\n",
    "                if connectivity == 1 and (abs(dx) + abs(dy) + abs(dz) > 1):\n",
    "                    continue  # 6-neighborhood\n",
    "                if connectivity == 2 and (abs(dx) + abs(dy) + abs(dz) > 2):\n",
    "                    continue  # ~18-neighborhood\n",
    "                offsets.append((dz, dy, dx))\n",
    "\n",
    "    # Count how many boundary voxels two labels share\n",
    "    touching_counts = defaultdict(int)\n",
    "\n",
    "    Z, Y, X = label_matrix.shape\n",
    "    for z in range(Z):\n",
    "        for y in range(Y):\n",
    "            for x in range(X):\n",
    "                c = label_matrix[z, y, x]\n",
    "                if c == 0:\n",
    "                    continue\n",
    "                for dz, dy, dx in offsets:\n",
    "                    nz = z + dz\n",
    "                    ny = y + dy\n",
    "                    nx = x + dx\n",
    "                    if nz < 0 or nz >= Z or ny < 0 or ny >= Y or nx < 0 or nx >= X:\n",
    "                        continue\n",
    "                    n = label_matrix[nz, ny, nx]\n",
    "                    if n == 0 or n == c:\n",
    "                        continue\n",
    "                    a, b = (c, n) if c < n else (n, c)\n",
    "                    touching_counts[(a, b)] += 1\n",
    "\n",
    "    # Union-Find initialization\n",
    "    all_labels = set(volumes.keys())\n",
    "    parent = {label: label for label in all_labels}\n",
    "\n",
    "    def find(u):\n",
    "        while parent[u] != u:\n",
    "            parent[u] = parent[parent[u]]\n",
    "            u = parent[u]\n",
    "        return u\n",
    "\n",
    "    def union(u, v):\n",
    "        pu, pv = find(u), find(v)\n",
    "        if pu != pv:\n",
    "            parent[pu] = pv\n",
    "\n",
    "    # Merge only if boundary is large enough\n",
    "    for (u, v), contact in touching_counts.items():\n",
    "        if u not in volumes or v not in volumes:\n",
    "            continue\n",
    "        vol_min = min(volumes[u], volumes[v])\n",
    "        rel_contact = contact / float(vol_min)\n",
    "        if contact >= contact_abs_min and rel_contact >= contact_rel_min:\n",
    "            union(u, v)\n",
    "\n",
    "    # Build label map: each label -> its root representative\n",
    "    label_map = {label: find(label) for label in all_labels}\n",
    "\n",
    "    # Apply merged labels\n",
    "    merged = np.zeros_like(label_matrix, dtype=np.int32)\n",
    "    for label, root in label_map.items():\n",
    "        merged[label_matrix == label] = root\n",
    "\n",
    "    # Re-label to get sequential labels starting from 1\n",
    "    merged, _, _ = relabel_sequential(merged)\n",
    "    return merged\n",
    "\n",
    "# def merge_touching_labels(label_matrix):\n",
    "#     \"\"\"Merge touching labels in a 3D label matrix using union-find.\"\"\"\n",
    "#     if label_matrix.max() == 0:\n",
    "#         return label_matrix.copy()\n",
    "\n",
    "#     padded = np.pad(label_matrix, 1, mode='constant', constant_values=0)\n",
    "#     touching = defaultdict(set)\n",
    "\n",
    "#     # Iterate over the inner volume (excluding padding)\n",
    "#     for z in range(1, padded.shape[0] - 1):\n",
    "#         for y in range(1, padded.shape[1] - 1):\n",
    "#             for x in range(1, padded.shape[2] - 1):\n",
    "#                 center = padded[z, y, x]\n",
    "#                 if center == 0:\n",
    "#                     continue\n",
    "#                 neighborhood = padded[z-1:z+2, y-1:y+2, x-1:x+2].ravel()\n",
    "#                 for neighbor in neighborhood:\n",
    "#                     if neighbor != center and neighbor != 0:\n",
    "#                         touching[center].add(neighbor)\n",
    "\n",
    "#     # Union-Find to merge touching labels\n",
    "#     all_labels = set(np.unique(label_matrix)) - {0}\n",
    "#     parent = {label: label for label in all_labels}\n",
    "\n",
    "#     def find(u):\n",
    "#         while parent[u] != u:\n",
    "#             parent[u] = parent[parent[u]]\n",
    "#             u = parent[u]\n",
    "#         return u\n",
    "\n",
    "#     def union(u, v):\n",
    "#         pu, pv = find(u), find(v)\n",
    "#         if pu != pv:\n",
    "#             parent[pu] = pv\n",
    "\n",
    "#     for u, neighbors in touching.items():\n",
    "#         for v in neighbors:\n",
    "#             if u in parent and v in parent:\n",
    "#                 union(u, v)\n",
    "\n",
    "#     label_map = {label: find(label) for label in all_labels}\n",
    "\n",
    "#     # Apply merged labels\n",
    "#     merged = np.zeros_like(label_matrix, dtype=np.int32)\n",
    "#     for label, root in label_map.items():\n",
    "#         merged[label_matrix == label] = root\n",
    "\n",
    "#     # Re-label to get sequential labels starting from 1\n",
    "#     merged, _, _ = relabel_sequential(merged)\n",
    "#     return merged\n",
    "\n",
    "def remove_small_islands(binary_matrix, area_threshold):\n",
    "    \"\"\"Remove small connected components from a binary mask.\"\"\"\n",
    "    labeled_array, num_features = label(binary_matrix)\n",
    "    for i in range(1, num_features + 1):\n",
    "        component = (labeled_array == i)\n",
    "        if component.sum() < area_threshold:\n",
    "            binary_matrix[component] = 0\n",
    "    return binary_matrix\n",
    "\n",
    "def assign_labels(A, B, connectivity=1):\n",
    "    \"\"\"Assign labels from B to islands in A based on overlap (3D).\"\"\"\n",
    "    if connectivity == 2:\n",
    "        structure = np.ones((3, 3, 3))  # 26-connectivity\n",
    "    else:\n",
    "        structure = None  # default is 6-connectivity for 3D\n",
    "\n",
    "    labeled_A, num_features = label(A, structure=structure)\n",
    "    C = np.zeros_like(A, dtype=B.dtype)\n",
    "\n",
    "    for i in range(1, num_features + 1):\n",
    "        mask = labeled_A == i\n",
    "        overlapping_labels = np.unique(B[mask & (B > 0)])\n",
    "        C[mask] = overlapping_labels[0] if len(overlapping_labels) > 0 else 0\n",
    "\n",
    "    return C\n",
    "\n",
    "def grow_labels(label_matrix,volume_factor=5.0):\n",
    "    structure = ball(volume_factor) #generate_binary_structure(3, 1)  # 6-connectivity in 3D\n",
    "    output = label_matrix.copy()\n",
    "    \n",
    "    labels = np.unique(label_matrix)\n",
    "    labels = labels[labels != 0]  # exclude background\n",
    "\n",
    "    # Compute original volumes\n",
    "    volumes = {label: np.sum(label_matrix == label) for label in labels}\n",
    "    target_volumes = {label: volume_factor * vol for label, vol in volumes.items()}\n",
    "\n",
    "    # Create masks for each label\n",
    "    label_masks = {label: (label_matrix == label) for label in labels}\n",
    "    grown_masks = label_masks.copy()\n",
    "\n",
    "    # Initialize growing flags\n",
    "    growing = {label: True for label in labels}\n",
    "\n",
    "    # Start growing iterations\n",
    "    while any(growing.values()):\n",
    "        new_masks = {}\n",
    "        occupied = np.zeros_like(label_matrix, dtype=bool)\n",
    "\n",
    "        # Prepare current occupied space\n",
    "        for label, mask in grown_masks.items():\n",
    "            occupied |= mask\n",
    "\n",
    "        for label in labels:\n",
    "            if not growing[label]:\n",
    "                continue\n",
    "            # Grow\n",
    "            dilated = binary_dilation(grown_masks[label], structure)\n",
    "            # Only grow into free space\n",
    "            new_mask = dilated & ~occupied\n",
    "            combined = grown_masks[label] | new_mask\n",
    "            if np.sum(combined) >= target_volumes[label]:\n",
    "                growing[label] = False\n",
    "            grown_masks[label] = combined\n",
    "            new_masks[label] = combined\n",
    "\n",
    "        # Update output matrix\n",
    "        output[:] = 0\n",
    "        for label, mask in grown_masks.items():\n",
    "            output[mask] = label\n",
    "\n",
    "    return output\n",
    "\n",
    "def stardist3d_from_2d(\n",
    "    img_3d,\n",
    "    model_name=\"2D_versatile_fluo\",\n",
    "    nucleus_radius=5,\n",
    "    voxel_size=(1.0, 0.5, 0.5),\n",
    "    norm=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply StarDist2D slice-by-slice to a 3D stack, merge predictions,\n",
    "    and split weakly connected nuclei using distance-based watershed.\n",
    "    Handles anisotropic voxel spacing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_3d : np.ndarray\n",
    "        Input 3D grayscale image, shape (Z, Y, X).\n",
    "    model_name : str\n",
    "        Name of pretrained StarDist2D model.\n",
    "    nucleus_radius : float\n",
    "        Approximate radius of nuclei in pixels (XY units).\n",
    "    voxel_size : tuple(float)\n",
    "        Physical voxel size as (z_spacing, y_spacing, x_spacing).\n",
    "    norm : bool\n",
    "        Normalize each 2D slice before prediction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels_split : np.ndarray\n",
    "        3D labeled array (int32), same shape as input.\n",
    "    \"\"\"\n",
    "\n",
    "    assert img_3d.ndim == 3, \"Input must be 3D (Z, Y, X)\"\n",
    "    z_spacing, y_spacing, x_spacing = voxel_size\n",
    "\n",
    "    print(f\"Running StarDist2D on {img_3d.shape[0]} z-slices...\")\n",
    "    model = StarDist2D.from_pretrained(model_name)\n",
    "\n",
    "    labels_3d = np.zeros_like(img_3d, dtype=np.int32)\n",
    "    current_label = 1\n",
    "\n",
    "    for z in range(img_3d.shape[0]):\n",
    "        img = img_3d[z]\n",
    "        if norm:\n",
    "            img = normalize(img, 1, 99.8, axis=None)\n",
    "\n",
    "        labels2d, _ = model.predict_instances(img)\n",
    "        labels2d = np.where(labels2d > 0, labels2d + current_label, 0)\n",
    "        labels_3d[z] = labels2d\n",
    "        current_label = labels2d.max() + 1\n",
    "\n",
    "    # Merge touching objects in 3D\n",
    "    labels_3d = skimage.measure.label(labels_3d > 0, connectivity=1)\n",
    "\n",
    "    # --- Anisotropic distance-based splitting ---\n",
    "    print(\"Computing distance transform with anisotropic voxel spacing...\")\n",
    "    distance = ndi.distance_transform_edt(labels_3d > 0, sampling=voxel_size)\n",
    "\n",
    "    # Estimate local maxima using nucleus_radius as search distance in XY\n",
    "    footprint = np.ones(\n",
    "        (\n",
    "            max(1, int(z_spacing / y_spacing)),  # thin in z\n",
    "            int(nucleus_radius),\n",
    "            int(nucleus_radius),\n",
    "        ),\n",
    "        dtype=bool,\n",
    "    )\n",
    "\n",
    "    local_max = peak_local_max(\n",
    "        distance,\n",
    "        footprint=footprint,\n",
    "        labels=labels_3d > 0,\n",
    "        exclude_border=False,\n",
    "    )\n",
    "\n",
    "    # Create markers for watershed\n",
    "    markers = np.zeros_like(labels_3d, dtype=int)\n",
    "    for i, coord in enumerate(local_max, start=1):\n",
    "        markers[tuple(coord)] = i\n",
    "\n",
    "    # Watershed segmentation\n",
    "    print(\"Running 3D watershed to split connected nuclei...\")\n",
    "    labels_split = watershed(-distance, markers, mask=labels_3d > 0)\n",
    "\n",
    "    print(f\"Done. Found {labels_split.max()} nuclei.\")\n",
    "    return labels_split\n",
    "\n",
    "\n",
    "# def stardist3d_from_2d(model_name='2D_versatile_fluo', img_3d=None, norm=True):\n",
    "#     \"\"\"\n",
    "#     Apply StarDist2D slice-by-slice to a 3D image stack and merge results.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     model_name : str\n",
    "#         Name of pretrained StarDist2D model (e.g. '2D_versatile_fluo').\n",
    "#     img_3d : np.ndarray\n",
    "#         Input 3D image of shape (Z, Y, X).\n",
    "#     norm : bool\n",
    "#         Whether to normalize each slice individually.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     labels_3d : np.ndarray\n",
    "#         3D labeled array of the same shape as img_3d.\n",
    "#     \"\"\"\n",
    "\n",
    "#     assert img_3d.ndim == 3, \"Input must be a 3D array (Z, Y, X).\"\n",
    "\n",
    "#     # Load pretrained 2D model\n",
    "#     model = StarDist2D.from_pretrained(model_name)\n",
    "\n",
    "#     labels_3d = np.zeros_like(img_3d, dtype=np.int32)\n",
    "#     current_label = 1\n",
    "\n",
    "#     for z in range(img_3d.shape[0]):\n",
    "#         img = img_3d[z]\n",
    "\n",
    "#         if norm:\n",
    "#             img = normalize(img, 1.0, 99.8, axis=None)\n",
    "\n",
    "#         # Predict 2D nuclei\n",
    "#         labels2d, _ = model.predict_instances(img)\n",
    "\n",
    "#         # Re-label so all IDs are unique across z\n",
    "#         labels2d = np.where(labels2d > 0, labels2d + current_label, 0)\n",
    "#         labels_3d[z] = labels2d\n",
    "#         current_label = labels2d.max() + 1\n",
    "\n",
    "#     # Optionally merge across z slices using 3D connectivity\n",
    "#     labels_3d = skimage.measure.label(labels_3d > 0, connectivity=1)\n",
    "\n",
    "#     return labels_3d\n",
    "\n",
    "def make_anisotropic_footprint(radius_Z, radius_Y, radius_X):\n",
    "    zz, yy, xx = np.ogrid[\n",
    "        -radius_Z:radius_Z+1,\n",
    "        -radius_Y:radius_Y+1,\n",
    "        -radius_X:radius_X+1\n",
    "    ]\n",
    "    ellipsoid = ((zz / radius_Z)**2 + (yy / radius_Y)**2 + (xx / radius_X)**2) <= 1\n",
    "    return ellipsoid\n",
    "\n",
    "def merge_small_touching_labels(label_matrix, size_threshold, z_weight=2.0):\n",
    "    \"\"\"\n",
    "    Merge small 3D labeled regions (< size_threshold) with touching neighbors,\n",
    "    preferentially merging into the largest touching label.\n",
    "    Large labels remain untouched.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label_matrix : np.ndarray (3D)\n",
    "        Labeled 3D array (e.g., watershed segmentation output).\n",
    "    size_threshold : int\n",
    "        Maximum voxel volume for a region to be considered \"small\".\n",
    "    z_weight : float, optional (default=2.0)\n",
    "        Weight factor to penalize Z-direction adjacency.\n",
    "        Use >1 for anisotropic stacks (Z spacing larger than XY).\n",
    "        Example: if Z spacing = 2 µm and XY = 0.5 µm, z_weight ≈ 4.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    merged : np.ndarray (3D)\n",
    "        Relabeled 3D matrix where small touching regions are merged\n",
    "        into larger neighbors, and all labels are renumbered sequentially.\n",
    "    \"\"\"\n",
    "\n",
    "    if label_matrix.max() == 0:\n",
    "        return label_matrix.copy()\n",
    "\n",
    "    # --- Step 1: Compute region properties ---\n",
    "    props = regionprops(label_matrix)\n",
    "    sizes = {p.label: p.area for p in props}\n",
    "    small_labels = {lbl for lbl, area in sizes.items() if area < size_threshold}\n",
    "\n",
    "    # --- Step 2: Build adjacency map (touching neighbors) ---\n",
    "    padded = np.pad(label_matrix, 1, mode='constant', constant_values=0)\n",
    "    touching = defaultdict(set)\n",
    "\n",
    "    z_range = [-1, 0, 1]\n",
    "    y_range = [-1, 0, 1]\n",
    "    x_range = [-1, 0, 1]\n",
    "\n",
    "    # Weighted neighborhood exploration for anisotropy\n",
    "    for z in range(1, padded.shape[0] - 1):\n",
    "        for y in range(1, padded.shape[1] - 1):\n",
    "            for x in range(1, padded.shape[2] - 1):\n",
    "                center = padded[z, y, x]\n",
    "                if center == 0:\n",
    "                    continue\n",
    "\n",
    "                # Explore 26-neighborhood\n",
    "                for dz in z_range:\n",
    "                    for dy in y_range:\n",
    "                        for dx in x_range:\n",
    "                            if dz == dy == dx == 0:\n",
    "                                continue\n",
    "                            neighbor = padded[z + dz, y + dy, x + dx]\n",
    "                            if neighbor == 0 or neighbor == center:\n",
    "                                continue\n",
    "\n",
    "                            # Apply anisotropic penalty: skip weak Z contacts\n",
    "                            if abs(dz) == 1 and (abs(dx) + abs(dy)) == 0:\n",
    "                                if np.random.random() < 1 / z_weight:\n",
    "                                    touching[center].add(neighbor)\n",
    "                            else:\n",
    "                                touching[center].add(neighbor)\n",
    "\n",
    "    # --- Step 3: Merge small regions with largest touching neighbor ---\n",
    "    merged = label_matrix.copy()\n",
    "\n",
    "    for lbl in sorted(small_labels):\n",
    "        mask = (merged == lbl)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "\n",
    "        neighbors = touching.get(lbl, set())\n",
    "        if not neighbors:\n",
    "            continue\n",
    "\n",
    "        # Choose the largest touching neighbor (prefer large ones)\n",
    "        neighbor_sizes = {n: sizes.get(n, 0) for n in neighbors if n not in small_labels}\n",
    "        if len(neighbor_sizes) == 0:\n",
    "            # If all neighbors are small, merge with the largest among them\n",
    "            neighbor_sizes = {n: sizes.get(n, 0) for n in neighbors}\n",
    "\n",
    "        if len(neighbor_sizes) == 0:\n",
    "            continue  # isolated small label\n",
    "\n",
    "        target_label = max(neighbor_sizes, key=neighbor_sizes.get)\n",
    "        merged[mask] = target_label\n",
    "\n",
    "    # --- Step 4: Relabel sequentially starting from 1 ---\n",
    "    merged, _, _ = relabel_sequential(merged)\n",
    "    return merged\n",
    "\n",
    "def voxel_volume(ri_x, ri_y, ri_z, zooms):\n",
    "    return (ri_x * ri_y * ri_z) / np.prod(zooms)\n",
    "\n",
    "def napari_contrast_gamma_uint8(image, contrast_limits, gamma):\n",
    "    \"\"\"\n",
    "    Apply Napari-style contrast limits + gamma correction,\n",
    "    and return the resulting image as uint8.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        Input image (any dtype).\n",
    "    contrast_limits : tuple (clim_min, clim_max)\n",
    "        Same values you see in Napari GUI.\n",
    "    gamma : float\n",
    "        Gamma value from Napari GUI.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out_uint8 : np.ndarray (uint8)\n",
    "        Image transformed exactly like Napari display,\n",
    "        then mapped to 0–255.\n",
    "    \"\"\"\n",
    "\n",
    "    clim_min, clim_max = contrast_limits\n",
    "\n",
    "    # Convert to float\n",
    "    img = image.astype(np.float32)\n",
    "\n",
    "    # Napari contrast normalization\n",
    "    img = (img - clim_min) / (clim_max - clim_min)\n",
    "    img = np.clip(img, 0.0, 1.0)\n",
    "\n",
    "    # Napari gamma\n",
    "    img = img ** gamma\n",
    "\n",
    "    # Convert display range [0,1] → uint8 [0,255]\n",
    "    out_uint8 = (img * 255).round().astype(np.uint8)\n",
    "\n",
    "    return out_uint8\n",
    "\n",
    "\n",
    "def compute_nuclei_cytoplasm_stats(seg_stack, r_xyz, zooms):\n",
    "    max_n = int(np.max(seg_stack['Nuclei']))\n",
    "    nuc_positions = []\n",
    "    nuc_sizes = []\n",
    "    cyto_positions = []\n",
    "    cyto_sizes = []\n",
    "\n",
    "    for n in range(1, max_n + 1):\n",
    "        zN, yN, xN = np.where(seg_stack['Nuclei'] == n)\n",
    "        if xN.size == 0:\n",
    "            nuc_positions.append((0.0, 0.0, 0.0))\n",
    "            nuc_sizes.append(0.0)\n",
    "        else:\n",
    "            nuc_positions.append((np.mean(xN * r_xyz[0] / zooms[2]), np.mean(yN * r_xyz[1] / zooms[1]), np.mean(zN * r_xyz[2] / zooms[0])))\n",
    "            nuc_sizes.append(xN.size * r_xyz[0] * r_xyz[1] * r_xyz[2] / np.prod(zooms))\n",
    "\n",
    "        zC, yC, xC = np.where(seg_stack['Cytoplasm'] == n)\n",
    "        if xC.size == 0:\n",
    "            cyto_positions.append((0.0, 0.0, 0.0))\n",
    "            cyto_sizes.append(0.0)\n",
    "        else:\n",
    "            cyto_positions.append((np.mean(xC * r_xyz[0] / zooms[2]), np.mean(yC * r_xyz[1] / zooms[1]), np.mean(zC * r_xyz[2] / zooms[0])))\n",
    "            cyto_sizes.append(xC.size * r_xyz[0] * r_xyz[1] * r_xyz[2] / np.prod(zooms))\n",
    "\n",
    "    return nuc_positions, nuc_sizes, cyto_positions, cyto_sizes\n",
    "\n",
    "\n",
    "def compute_marker_stats_for_marker(marker_idx, seg_stack, filtered_img, r_xyz, zooms):\n",
    "    \"\"\"Compute marker stats per nucleus for a single marker channel.\n",
    "    Returns: shared_labels (list of nucleus IDs), marker_sizes (list), avg_marker (list),\n",
    "    marker_cyto_sizes, avg_cyto_marker, marker_pcm_sizes, avg_pcm_marker\n",
    "    \"\"\"\n",
    "    # Identify marker names/keys used in seg_stack\n",
    "    condition = stain_complete_df.index[marker_idx]\n",
    "    marker_name = stain_complete_df['Marker'][marker_idx]\n",
    "\n",
    "    # Keys in im_segmentation_stack: use condition (e.g., 'MACRO') and suffixes\n",
    "    key_base = stain_df.index[marker_idx] if stain_df.index.name is not None else condition\n",
    "    # In this pipeline, im_segmentation_stack stores keys as condition names (same as stain_df.index)\n",
    "    seg_key = stain_df.index[marker_idx]\n",
    "\n",
    "    # If marker images were stored as intensity*mask earlier, use those\n",
    "    marker_img = seg_stack.get(seg_key, None)\n",
    "    marker_img_cyto = seg_stack.get(seg_key + '_cyto', None)\n",
    "    marker_img_pcm = seg_stack.get(seg_key + '_PCM', None)\n",
    "\n",
    "    max_n = int(np.max(seg_stack['Nuclei']))\n",
    "\n",
    "    shared_labels = []\n",
    "    marker_sizes = []\n",
    "    avg_marker = []\n",
    "    std_marker = []\n",
    "    marker_cyto_sizes = []\n",
    "    avg_cyto_marker = []\n",
    "    std_cyto_marker = []\n",
    "    marker_pcm_sizes = []\n",
    "    avg_pcm_marker = []\n",
    "    std_pcm_marker = []\n",
    "    #list_marker = []\n",
    "\n",
    "    # If no marker images present, return empty lists\n",
    "    if marker_img is None:\n",
    "        return shared_labels, marker_sizes, avg_marker, marker_cyto_sizes, avg_cyto_marker, marker_pcm_sizes, avg_pcm_marker\n",
    "\n",
    "    # For intensity lookup, pick the same channel index in filtered_img\n",
    "    # Find which channel index corresponds to this condition\n",
    "    ch_idx = None\n",
    "    for i, idx in enumerate(stain_complete_df.index):\n",
    "        if idx == condition:\n",
    "            ch_idx = i\n",
    "            break\n",
    "\n",
    "    for n in range(1, max_n + 1):\n",
    "        nuc_mask = (seg_stack['Nuclei'] == n)\n",
    "        cyto_mask = (seg_stack['Cytoplasm'] == n)\n",
    "        PCM_mask = (seg_stack['PCM'] == n)\n",
    "        # Marker presence in the nucleus/cell region\n",
    "        mask_marker_in_nucleus = (marker_img > 0) & ((nuc_mask+cyto_mask+PCM_mask) > 0)\n",
    "        if np.any(mask_marker_in_nucleus):\n",
    "            shared_labels.append(n)\n",
    "            # marker_total (cytoplasm+PCM) measured on marker_img\n",
    "            voxels = np.where(mask_marker_in_nucleus)\n",
    "            count = voxels[0].size\n",
    "            vol = count * voxel_volume(r_xyz[0], r_xyz[1], r_xyz[2], zooms)\n",
    "            marker_sizes.append(vol)\n",
    "            if ch_idx is not None:\n",
    "                vals = filtered_img[voxels[0], voxels[1], voxels[2], ch_idx]\n",
    "                avg_marker.append(float(np.mean(vals)) if vals.size>0 else 0.0)\n",
    "                std_marker.append(float(np.std(vals)) if vals.size>0 else 0.0)\n",
    "                # list_marker.append(vals if vals.size>0 else 0.0)\n",
    "            else:\n",
    "                avg_marker.append(0.0)\n",
    "                std_marker.append(0.0)\n",
    "\n",
    "            # cytoplasm-only\n",
    "            if marker_img_cyto is not None:\n",
    "                mask_marker_cyto = (marker_img_cyto > 0) & cyto_mask\n",
    "                vox_c = np.where(mask_marker_cyto)\n",
    "                count_c = vox_c[0].size\n",
    "                marker_cyto_sizes.append(count_c * voxel_volume(r_xyz[0], r_xyz[1], r_xyz[2], zooms))\n",
    "                if ch_idx is not None and count_c>0:\n",
    "                    vals_c = filtered_img[vox_c[0], vox_c[1], vox_c[2], ch_idx]\n",
    "                    avg_cyto_marker.append(float(np.mean(vals_c)))\n",
    "                    std_cyto_marker.append(float(np.std(vals_c)))\n",
    "                else:\n",
    "                    avg_cyto_marker.append(0.0)\n",
    "                    std_cyto_marker.append(0.0)\n",
    "            else:\n",
    "                marker_cyto_sizes.append(0.0)\n",
    "                avg_cyto_marker.append(0.0)\n",
    "                std_cyto_marker.append(0.0)\n",
    "\n",
    "            # pcm-only\n",
    "            if marker_img_pcm is not None:\n",
    "                mask_marker_pcm = (marker_img_pcm > 0) & PCM_mask\n",
    "                vox_p = np.where(mask_marker_pcm)\n",
    "                count_p = vox_p[0].size\n",
    "                marker_pcm_sizes.append(count_p * voxel_volume(r_xyz[0], r_xyz[1], r_xyz[2], zooms))\n",
    "                if ch_idx is not None and count_p>0:\n",
    "                    vals_p = filtered_img[vox_p[0], vox_p[1], vox_p[2], ch_idx]\n",
    "                    avg_pcm_marker.append(float(np.mean(vals_p)))\n",
    "                    std_pcm_marker.append(float(np.std(vals_p)))\n",
    "                else:\n",
    "                    avg_pcm_marker.append(0.0)\n",
    "                    std_pcm_marker.append(0.0)\n",
    "            else:\n",
    "                marker_pcm_sizes.append(0.0)\n",
    "                avg_pcm_marker.append(0.0)\n",
    "                std_pcm_marker.append(0.0)\n",
    "\n",
    "    return shared_labels, marker_sizes, avg_marker, std_marker, marker_cyto_sizes, avg_cyto_marker, std_cyto_marker, marker_pcm_sizes, avg_pcm_marker, std_pcm_marker\n",
    "\n",
    "def compute_full_marker_stats_for_marker(marker_idx, seg_final, seg_stack, filtered_img, r_xyz, zooms):\n",
    "    \"\"\"Compute marker stats per nucleus for a single marker channel.\n",
    "    Returns: shared_labels (list of nucleus IDs), marker_sizes (list), avg_marker (list),\n",
    "    marker_cyto_sizes, avg_cyto_marker, marker_pcm_sizes, avg_pcm_marker\n",
    "    \"\"\"\n",
    "    # Identify marker names/keys used in seg_stack\n",
    "    condition = stain_complete_df.index[marker_idx]\n",
    "    marker_name = stain_complete_df['Marker'][marker_idx]\n",
    "\n",
    "    # Keys in im_segmentation_stack: use condition (e.g., 'MACRO') and suffixes\n",
    "    key_base = stain_df.index[marker_idx] if stain_df.index.name is not None else condition\n",
    "    # In this pipeline, im_segmentation_stack stores keys as condition names (same as stain_df.index)\n",
    "    seg_key = stain_df.index[marker_idx]\n",
    "\n",
    "    # If marker images were stored as intensity*mask earlier, use those\n",
    "    marker_img = seg_final['Filtered image'][:,:,:,marker_idx]\n",
    "    # marker_img_cyto = seg_stack.get(seg_key + '_cyto', None)\n",
    "    # marker_img_pcm = seg_stack.get(seg_key + '_PCM', None)\n",
    "\n",
    "    max_n = int(np.max(seg_stack['Nuclei']))\n",
    "\n",
    "    shared_labels = []\n",
    "    marker_sizes = []\n",
    "    avg_marker = []\n",
    "    std_marker = []\n",
    "    marker_cyto_sizes = []\n",
    "    avg_cyto_marker = []\n",
    "    std_cyto_marker = []\n",
    "    marker_pcm_sizes = []\n",
    "    avg_pcm_marker = []\n",
    "    std_pcm_marker = []\n",
    "    #list_marker = []\n",
    "\n",
    "    # If no marker images present, return empty lists\n",
    "    if marker_img is None:\n",
    "        return shared_labels, marker_sizes, avg_marker, marker_cyto_sizes, avg_cyto_marker, marker_pcm_sizes, avg_pcm_marker\n",
    "\n",
    "    # For intensity lookup, pick the same channel index in filtered_img\n",
    "    # Find which channel index corresponds to this condition\n",
    "    ch_idx = None\n",
    "    for i, idx in enumerate(stain_complete_df.index):\n",
    "        if idx == condition:\n",
    "            ch_idx = i\n",
    "            break\n",
    "\n",
    "    for n in range(1, max_n + 1):\n",
    "        nuc_mask = (seg_stack['Nuclei'] == n)\n",
    "        cyto_mask = (seg_stack['Cytoplasm'] == n)\n",
    "        PCM_mask = (seg_stack['PCM'] == n)\n",
    "        # Marker presence in the nucleus/cell region\n",
    "        mask_marker_in_nucleus = ((nuc_mask+cyto_mask+PCM_mask) > 0) & (marker_img > 0) \n",
    "        #if np.any(mask_marker_in_nucleus):\n",
    "        shared_labels.append(n)\n",
    "        \n",
    "        # marker_total (cytoplasm+PCM) measured on marker_img\n",
    "        voxels = np.where(mask_marker_in_nucleus)\n",
    "        count = voxels[0].size\n",
    "        vol = count * voxel_volume(r_xyz[0], r_xyz[1], r_xyz[2], zooms)\n",
    "        marker_sizes.append(vol)\n",
    "        if ch_idx is not None:\n",
    "            vals = filtered_img[voxels[0], voxels[1], voxels[2], ch_idx]\n",
    "            avg_marker.append(float(np.mean(vals)) if vals.size>0 else 0.0)\n",
    "            std_marker.append(float(np.std(vals)) if vals.size>0 else 0.0)\n",
    "            # list_marker.append(vals if vals.size>0 else 0.0)\n",
    "        else:\n",
    "            avg_marker.append(0.0)\n",
    "            std_marker.append(0.0)\n",
    "\n",
    "        # cytoplasm-only\n",
    "        #if marker_img_cyto is not None:\n",
    "        mask_marker_cyto = (marker_img > 0) & cyto_mask\n",
    "        vox_c = np.where(mask_marker_cyto)\n",
    "        count_c = vox_c[0].size\n",
    "        marker_cyto_sizes.append(count_c * voxel_volume(r_xyz[0], r_xyz[1], r_xyz[2], zooms))\n",
    "        if ch_idx is not None and count_c>0:\n",
    "            vals_c = filtered_img[vox_c[0], vox_c[1], vox_c[2], ch_idx]\n",
    "            avg_cyto_marker.append(float(np.mean(vals_c)))\n",
    "            std_cyto_marker.append(float(np.std(vals_c)))\n",
    "        else:\n",
    "            avg_cyto_marker.append(0.0)\n",
    "            std_cyto_marker.append(0.0)\n",
    "        # else:\n",
    "        #     marker_cyto_sizes.append(0.0)\n",
    "        #     avg_cyto_marker.append(0.0)\n",
    "        #     std_cyto_marker.append(0.0)\n",
    "\n",
    "        # pcm-only\n",
    "        # if marker_img_pcm is not None:\n",
    "        mask_marker_pcm = (marker_img > 0) & PCM_mask\n",
    "        vox_p = np.where(mask_marker_pcm)\n",
    "        count_p = vox_p[0].size\n",
    "        marker_pcm_sizes.append(count_p * voxel_volume(r_xyz[0], r_xyz[1], r_xyz[2], zooms))\n",
    "        if ch_idx is not None and count_p>0:\n",
    "            vals_p = filtered_img[vox_p[0], vox_p[1], vox_p[2], ch_idx]\n",
    "            avg_pcm_marker.append(float(np.mean(vals_p)))\n",
    "            std_pcm_marker.append(float(np.std(vals_p)))\n",
    "        else:\n",
    "            avg_pcm_marker.append(0.0)\n",
    "            std_pcm_marker.append(0.0)\n",
    "        # else:\n",
    "        #     marker_pcm_sizes.append(0.0)\n",
    "        #     avg_pcm_marker.append(0.0)\n",
    "        #     std_pcm_marker.append(0.0)\n",
    "\n",
    "    return shared_labels, marker_sizes, avg_marker, std_marker, marker_cyto_sizes, avg_cyto_marker, std_cyto_marker, marker_pcm_sizes, avg_pcm_marker, std_pcm_marker\n",
    "\n",
    "def save_raw_png(arr, filename, contrast_limits=None, gamma=None):\n",
    "    \"\"\"\n",
    "    Save a 2D numpy array to PNG while optionally applying Napari-style\n",
    "    contrast limits and gamma so saved images match displayed intensities.\n",
    "\n",
    "    Parameters\n",
    "    - arr: 2D array-like\n",
    "    - filename: output path\n",
    "    - contrast_limits: tuple (min, max) to map to [0,1] before gamma (optional)\n",
    "    - gamma: gamma exponent to apply after contrast (optional)\n",
    "\n",
    "    Backwards-compatible: if no contrast_limits provided, tries to preserve\n",
    "    dtype and dynamic range as before.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "\n",
    "    # If user requested Napari-style mapping, use helper\n",
    "    if contrast_limits is not None:\n",
    "        clim = contrast_limits\n",
    "        g = 1.0 if gamma is None else float(gamma)\n",
    "        try:\n",
    "            out = napari_contrast_gamma_uint8(arr.astype(np.float32), (float(clim[0]), float(clim[1])), g)\n",
    "            img = PILImage.fromarray(out)\n",
    "            img.save(filename)\n",
    "            return filename\n",
    "        except Exception:\n",
    "            # fallback to naive save below\n",
    "            pass\n",
    "\n",
    "    # --- Fallback / legacy behavior ---\n",
    "    # Already uint8/uint16 → save as-is\n",
    "    if arr.dtype == np.uint8 or arr.dtype == np.uint16:\n",
    "        img = PILImage.fromarray(arr)\n",
    "        img.save(filename)\n",
    "        return filename\n",
    "\n",
    "    # Float data: scale by max to choose appropriate depth\n",
    "    if np.issubdtype(arr.dtype, np.floating):\n",
    "        maxv = float(arr.max()) if arr.size else 0.0\n",
    "        if maxv == 0:\n",
    "            arr8 = np.zeros_like(arr, dtype=np.uint8)\n",
    "            img = PILImage.fromarray(arr8)\n",
    "            img.save(filename)\n",
    "            return filename\n",
    "\n",
    "        if maxv <= 255:\n",
    "            arr_scaled = (arr / maxv) * 255.0\n",
    "            arr_scaled = np.clip(arr_scaled, 0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            arr_scaled = (arr / maxv) * 65535.0\n",
    "            arr_scaled = np.clip(arr_scaled, 0, 65535).astype(np.uint16)\n",
    "\n",
    "        img = PILImage.fromarray(arr_scaled)\n",
    "        img.save(filename)\n",
    "        return filename\n",
    "\n",
    "    # Integer types other than uint8/uint16\n",
    "    if np.issubdtype(arr.dtype, np.integer):\n",
    "        maxv = int(arr.max()) if arr.size else 0\n",
    "        if maxv <= 255:\n",
    "            arr8 = arr.astype(np.uint8)\n",
    "            img = PILImage.fromarray(arr8)\n",
    "            img.save(filename)\n",
    "            return filename\n",
    "        elif maxv <= 65535:\n",
    "            arr16 = arr.astype(np.uint16)\n",
    "            img = PILImage.fromarray(arr16)\n",
    "            img.save(filename)\n",
    "            return filename\n",
    "        else:\n",
    "            arr16 = (arr / maxv * 65535).astype(np.uint16)\n",
    "            img = PILImage.fromarray(arr16)\n",
    "            img.save(filename)\n",
    "            return filename\n",
    "\n",
    "    raise ValueError(\"Unsupported dtype for PNG saving.\")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Minimal ImageProcessing wrapper\n",
    "# --------------------------------------------------------------------\n",
    "class ImageProcessing:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.img = PILImage.open(filename)\n",
    "\n",
    "    def as_np(self):\n",
    "        return np.array(self.img)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Utility: save a 2D array as grayscale PNG\n",
    "# --------------------------------------------------------------------\n",
    "def save_single_channel_png(img2d, fname):\n",
    "    \"\"\"\n",
    "    Save a 2D image to PNG with adaptive scaling:\n",
    "    - Keeps original intensities for analysis\n",
    "    - Stretch to 0–255 only for visualization\n",
    "    \"\"\"\n",
    "    if img2d is None or img2d.size == 0:\n",
    "        return None\n",
    "\n",
    "    arr = np.array(img2d, dtype=float)\n",
    "\n",
    "    # Adaptive visualization scaling\n",
    "    vmin = np.percentile(arr, 1)\n",
    "    vmax = np.percentile(arr, 99)\n",
    "\n",
    "    if vmax <= vmin:\n",
    "        vmax = vmin + 1e-6\n",
    "\n",
    "    arr_vis = (arr - vmin) / (vmax - vmin)\n",
    "    arr_vis = np.clip(arr_vis * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "    img = PILImage.fromarray(arr_vis)\n",
    "    img.save(fname)\n",
    "    return fname\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Crop nucleus (3D-aware)\n",
    "# --------------------------------------------------------------------\n",
    "def crop_nucleus_with_padding(nucleus_mask, full_img_stack, pad=20):\n",
    "    \"\"\"\n",
    "    nucleus_mask: 3D boolean array\n",
    "    full_img_stack: dict {cond: 3D array}\n",
    "    \"\"\"\n",
    "    # pick best z slice\n",
    "    if nucleus_mask.ndim == 3:\n",
    "        z_counts = nucleus_mask.sum(axis=(1, 2))\n",
    "        best_z = int(np.argmax(z_counts))\n",
    "        nuc2d = nucleus_mask[best_z]\n",
    "    else:\n",
    "        best_z = 0\n",
    "        nuc2d = nucleus_mask\n",
    "\n",
    "    ys, xs = np.where(nuc2d)\n",
    "    if len(xs) == 0:\n",
    "        return None, best_z, None, None\n",
    "\n",
    "    # bounding box\n",
    "    y_min0 = max(0, ys.min() - pad)\n",
    "    y_max0 = ys.max() + pad\n",
    "    x_min0 = max(0, xs.min() - pad)\n",
    "    x_max0 = xs.max() + pad\n",
    "\n",
    "    crop_dict = {}\n",
    "    heights, widths = [], []\n",
    "\n",
    "    # crop each condition\n",
    "    for cond, img3D in full_img_stack.items():\n",
    "        Z, H_full, W_full = img3D.shape\n",
    "\n",
    "        y_min = y_min0\n",
    "        y_max = min(y_max0, H_full)\n",
    "        x_min = x_min0\n",
    "        x_max = min(x_max0, W_full)\n",
    "\n",
    "        # keep original intensities (do not normalize here)\n",
    "        cropped = img3D[best_z, y_min:y_max, x_min:x_max].astype(float)\n",
    "\n",
    "        crop_dict[cond] = cropped\n",
    "        heights.append(cropped.shape[0])\n",
    "        widths.append(cropped.shape[1])\n",
    "\n",
    "    min_H = int(min(heights)) if heights else 0\n",
    "    min_W = int(min(widths)) if widths else 0\n",
    "\n",
    "    return crop_dict, best_z, (y_min0, x_min0), (min_H, min_W)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Get channel titles from stain_df\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def get_stain_name(stain_df, key):\n",
    "    \"\"\"\n",
    "    Accepts:\n",
    "      - stain_df as dict-like (stain_df[key])\n",
    "      - OR pandas DataFrame (stain_df.loc[key, 'stain_name'])\n",
    "\n",
    "    Returns a clean string for the title.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Case 1: dictionary-like\n",
    "        return str(stain_df[key])\n",
    "    except Exception:\n",
    "        try:\n",
    "            # Case 2: dataframe with a column 'stain_name'\n",
    "            return str(stain_df.loc[key, 'stain_name'])\n",
    "        except Exception:\n",
    "            # Fallback\n",
    "            return key\n",
    "\n",
    "# Build and save merged RGB with Napari contrast/gamma applied\n",
    "def save_merged_figure(\n",
    "    nucleus_mask, full_img_stack, condition_colors, nucleus_id,\n",
    "    seg_stack,  # NEW: pass seg_stack for cyto/PCM masks\n",
    "    nucleus_color='blue', cytoplasm_color='green', pcm_color='magenta',\n",
    "    pad=20, out_dir=\"merged_png\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Build merged RGB: nuclei (blue) + cytoplasm (green) + PCM (magenta) + marker overlay.\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    crop_dict, best_z, (y0, x0), (min_H, min_W) = crop_nucleus_with_padding(nucleus_mask, full_img_stack, pad=pad)\n",
    "    if crop_dict is None or min_H <= 0 or min_W <= 0:\n",
    "        return None\n",
    "\n",
    "    # Initialize black RGB\n",
    "    merged_rgb = np.zeros((min_H, min_W, 3), dtype=float)\n",
    "\n",
    "    structure_opacity = 0.2\n",
    "    white_rgb = np.array([1.0, 1.0, 1.0])  # Pure white\n",
    "    blue_rgb = np.array([0.0,0.0,1.0])\n",
    "    \n",
    "    # 1. Nuclei (white @ 20%)\n",
    "    if nucleus_mask.ndim == 3:\n",
    "        nuc2d = nucleus_mask[best_z]\n",
    "    else:\n",
    "        nuc2d = nucleus_mask\n",
    "    nuc_crop = nuc2d[y0:y0+min_H, x0:x0+min_W].astype(float)\n",
    "    merged_rgb += nuc_crop[..., None] * blue_rgb * structure_opacity\n",
    "    \n",
    "    # 2+3. Dashed contours around cytoplasm + PCM (white, 20% opacity)\n",
    "    structure_opacity = 0.2\n",
    "    white_rgb = np.array([1.0, 1.0, 1.0])\n",
    "    \n",
    "    # Combined cyto + PCM mask\n",
    "    cyto_mask = (seg_stack.get('Cytoplasm', np.zeros_like(nucleus_mask)) == nucleus_id)\n",
    "    pcm_mask = (seg_stack.get('PCM', np.zeros_like(nucleus_mask)) == nucleus_id)\n",
    "    combined_mask = cyto_mask | pcm_mask  # Union of both\n",
    "    \n",
    "    if np.any(combined_mask):\n",
    "        # Use best_z slice\n",
    "        if combined_mask.ndim == 3:\n",
    "            combined_2d = combined_mask[best_z]\n",
    "        else:\n",
    "            combined_2d = combined_mask\n",
    "        \n",
    "        # Crop\n",
    "        combined_crop = combined_2d[y0:y0+min_H, x0:x0+min_W].astype(float)\n",
    "        \n",
    "        # Create dashed contour (3px thick, 50% dash:gap)\n",
    "        from skimage.measure import find_contours\n",
    "        contours = find_contours(combined_crop, 0.5, fully_connected='low')\n",
    "        \n",
    "        # Draw on temp RGB canvas\n",
    "        contour_rgb = np.zeros((min_H, min_W, 3), dtype=float)\n",
    "        for contour in contours:\n",
    "            # Scale contour coords back to image space\n",
    "            contour[:, 0] *= min_H / combined_crop.shape[0]  # y\n",
    "            contour[:, 1] *= min_W / combined_crop.shape[1]  # x\n",
    "            \n",
    "            # Integer positions for drawing\n",
    "            contour_int = contour.astype(int)\n",
    "            \n",
    "            # Dash pattern: every other pixel\n",
    "            for i in range(0, len(contour_int), 2):  # Step 2 for dash/gap\n",
    "                if i+1 < len(contour_int):\n",
    "                    # Draw 2px line segments\n",
    "                    rr, cc = draw_line(int(contour_int[i,0]), int(contour_int[i,1]),\n",
    "                                       int(contour_int[i+1,0]), int(contour_int[i+1,1]))\n",
    "                    contour_rgb[rr, cc] = white_rgb * structure_opacity\n",
    "        \n",
    "        merged_rgb += contour_rgb\n",
    "\n",
    "    # 4. Marker channels (additive overlay)\n",
    "    for cond, img in crop_dict.items():\n",
    "        img_small = img[:min_H, :min_W].copy()\n",
    "        \n",
    "        # Napari contrast/gamma\n",
    "        if (cond in stain_complete_df.index) and ('Cont_min' in stain_complete_df.columns):\n",
    "            try:\n",
    "                clim = (stain_complete_df.loc[cond, 'Cont_min'], stain_complete_df.loc[cond, 'Cont_max'])\n",
    "                gamma = stain_complete_df.loc[cond, 'Gamma'] if 'Gamma' in stain_complete_df.columns else 1.0\n",
    "                img_display = napari_contrast_gamma_uint8(img_small.astype(np.float32), \n",
    "                                                          (float(clim[0]), float(clim[1])), \n",
    "                                                          float(gamma))\n",
    "                img_normalized = img_display.astype(float) / 255.0\n",
    "            except:\n",
    "                img_normalized = img_small / (img_small.max() + 1e-6)\n",
    "        else:\n",
    "            img_normalized = img_small / (img_small.max() + 1e-6)\n",
    "        \n",
    "        color = np.array(mcolors.to_rgb(condition_colors.get(cond, 'gray')))\n",
    "        merged_rgb += img_normalized[..., None] * color * 0.6  # Transparent overlay\n",
    "\n",
    "    # Clip and convert to uint8\n",
    "    merged_rgb = np.clip(merged_rgb, 0, 1.0)\n",
    "    merged_uint8 = (merged_rgb * 255).astype(np.uint8)\n",
    "\n",
    "    # Save PNG filename (not array)\n",
    "    fname = os.path.join(out_dir, f\"n{nucleus_id}_merged.png\")\n",
    "    PILImage.fromarray(merged_uint8).save(fname)\n",
    "    return fname  # Return filename directly\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Main PDF creator\n",
    "# --------------------------------------------------------------------\n",
    "def create_row_pdf(output_pdf=\"nuclei_row_pages.pdf\", pad=20, thumb_size=(2.2*inch, 2.2*inch)):\n",
    "\n",
    "    doc = SimpleDocTemplate(output_pdf, pagesize=A4)\n",
    "    story = []\n",
    "\n",
    "    nuclei = sorted(hist_data.keys())\n",
    "    if not nuclei:\n",
    "        raise ValueError(\"hist_data is empty.\")\n",
    "\n",
    "    # derive 3 marker channels\n",
    "    all_conditions = sorted({cond for nd in hist_data.values() for cond in nd.keys()})\n",
    "    marker_conditions = [c for c in all_conditions if c.lower() != 'nuclei']\n",
    "    marker_conditions = (marker_conditions + marker_conditions)[:3]\n",
    "\n",
    "    # color map\n",
    "    condition_colors = {\n",
    "        cond: (\n",
    "            stain_complete_df.loc[cond, 'Color']\n",
    "            if cond in stain_complete_df.index and 'Color' in stain_complete_df.columns\n",
    "            else 'gray'\n",
    "        )\n",
    "        for cond in marker_conditions\n",
    "    }\n",
    "    condition_colors = {k: ('gray' if v == 'WHITE' else v) for k, v in condition_colors.items()}\n",
    "\n",
    "    nucleus_color = (\n",
    "        stain_df.loc['NUCLEI', 'Color']\n",
    "        if ('NUCLEI' in stain_df.index and 'Color' in stain_df.columns)\n",
    "        else 'blue'\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # LOOP OVER NUCLEI\n",
    "    # ---------------------------------------------------------\n",
    "    for n in nuclei:\n",
    "\n",
    "        # collect per-channel stack\n",
    "        full_stack = {}\n",
    "        for cond in marker_conditions:\n",
    "            ch_inds = np.where(stain_complete_df.index == cond)[0]\n",
    "            if len(ch_inds):\n",
    "                full_stack[cond] = filtered_img[:, :, :, ch_inds[0]]\n",
    "\n",
    "        nucleus_mask = (seg_stack['Nuclei'] == n)\n",
    "\n",
    "        crop_dict_all, best_z, (y0, x0), (min_H, min_W) = \\\n",
    "            crop_nucleus_with_padding(nucleus_mask, full_stack, pad=pad)\n",
    "\n",
    "        if crop_dict_all is None:\n",
    "            story.append(Paragraph(f\"<b>Nucleus {n}</b>: no pixels found\", styles['Heading2']))\n",
    "            story.append(Spacer(1, 0.3 * inch))\n",
    "            continue\n",
    "\n",
    "        # ------------------ Save channel crops ------------------\n",
    "        os.makedirs(\"crop_png\", exist_ok=True)\n",
    "        ch_pngs = []\n",
    "\n",
    "        for cond in marker_conditions:\n",
    "            img = crop_dict_all.get(cond)\n",
    "            arr = np.zeros((min_H, min_W)) if img is None or img.size == 0 else img[:min_H, :min_W]\n",
    "            fname = f\"crop_png/n{n}_{cond}.png\"\n",
    "            # Use stored Napari contrast limits + gamma when available so saved crops\n",
    "            # keep the same displayed intensity mapping as in the viewer.\n",
    "            if (cond in stain_complete_df.index) and ('Cont_min' in stain_complete_df.columns):\n",
    "                try:\n",
    "                    clim = (stain_complete_df.loc[cond, 'Cont_min'], stain_complete_df.loc[cond, 'Cont_max'])\n",
    "                    gamma = stain_complete_df.loc[cond, 'Gamma'] if 'Gamma' in stain_complete_df.columns else 1.0\n",
    "                    save_raw_png(arr, fname, contrast_limits=clim, gamma=gamma)\n",
    "                except Exception:\n",
    "                    save_raw_png(arr, fname)\n",
    "            else:\n",
    "                save_raw_png(arr, fname)\n",
    "            ch_pngs.append(fname)\n",
    "\n",
    "        # ------------------ Save merged ------------------\n",
    "        merged_png = save_merged_figure(\n",
    "            nucleus_mask, full_stack, condition_colors, n,\n",
    "            seg_stack=seg_stack,  # NEW: pass seg_stack\n",
    "            nucleus_color=nucleus_color,\n",
    "            cytoplasm_color='green', pcm_color='magenta',\n",
    "            pad=pad, out_dir=\"merged_png\"\n",
    "        )\n",
    "        \n",
    "        if merged_png is None:  # Now returns filename or None\n",
    "            merged_arr = np.zeros((min_H, min_W))\n",
    "            merged_png = f\"merged_png/n{n}_merged_placeholder.png\"\n",
    "            save_raw_png(merged_arr, merged_png)\n",
    "        # else:\n",
    "        #     merged_arr = ImageProcessing(merged_raw).as_np()\n",
    "        #     merged_arr = merged_arr[:min_H, :min_W]\n",
    "        #     merged_png = f\"merged_png/n{n}_merged_fixed.png\"\n",
    "        #     save_raw_png(merged_arr, merged_png)\n",
    "\n",
    "        # ------------------ Density plot ------------------\n",
    "        os.makedirs(\"density_png\", exist_ok=True)\n",
    "        fig, ax = plt.subplots(figsize=(4, 2.2))\n",
    "        #ax.set_title(f\"Nucleus {n}\")\n",
    "        ax.set_xlim(0, 255)\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.grid(alpha=0.2)\n",
    "    \n",
    "        # For each condition, plot density if data exists\n",
    "        for cond in all_conditions:\n",
    "            vals = np.array(hist_data.get(n, {}).get(cond, []))\n",
    "            if stain_complete_df['Color'][cond] != 'WHITE':\n",
    "                color = stain_complete_df['Color'][cond]  \n",
    "            else:\n",
    "                color = 'GRAY'\n",
    "    \n",
    "            if vals.size == 0:\n",
    "                # no data for this nucleus & condition: skip curve plotting\n",
    "                continue\n",
    "    \n",
    "            # try KDE, fallback if singular\n",
    "            y_grid = None\n",
    "            try:\n",
    "                kde = gaussian_kde(vals)\n",
    "                y_grid = kde(x_grid)\n",
    "            except Exception:\n",
    "                # fallback: create a narrow Gaussian around the mean (handles zero-variance)\n",
    "                mean_val = vals.mean()\n",
    "                bw = 1.0  # small bandwidth fallback\n",
    "                y_grid = np.exp(-0.5 * ((x_grid - mean_val) / bw) ** 2)\n",
    "            \n",
    "            # normalize y to 0-1\n",
    "            if y_grid.max() > 0:\n",
    "                y_norm = y_grid / y_grid.max()\n",
    "            else:\n",
    "                y_norm = y_grid\n",
    "    \n",
    "            # plot density curve\n",
    "            ax.plot(x_grid, y_norm, linewidth=2, color=color)\n",
    "    \n",
    "            # compute mean and std from raw vals\n",
    "            mean_val = float(vals.mean())\n",
    "            std_val = float(vals.std())\n",
    "    \n",
    "            # vertical mean line (same color)\n",
    "            ax.axvline(mean_val, linestyle='--', linewidth=1.5, color=color)\n",
    "    \n",
    "            # y position for std-line: read normalized KDE at mean (interpolate)\n",
    "            y_at_mean = np.interp(mean_val, x_grid, y_norm)\n",
    "    \n",
    "            # horizontal std line from mean-std to mean+std (clamped to axis)\n",
    "            x_start = max(0.0, mean_val - std_val)\n",
    "            x_end = min(255.0, mean_val + std_val)\n",
    "            ax.hlines(y_at_mean, x_start, x_end, linewidth=2, color=color)\n",
    "\n",
    "            #ax.text(x_end, y_at_mean, str(mean_val) + \" SD:\" + str(std_val), color = color)\n",
    "    \n",
    "        # Build a legend showing all conditions with their assigned color (consistent across plots)\n",
    "        legend_handles = [Line2D([0], [0], color=stain_complete_df['Color'][c] if stain_complete_df['Color'][c] != 'WHITE' else 'GRAY', lw=2) for c in all_conditions]\n",
    "        ax.legend(legend_handles, all_conditions, loc='upper right', framealpha=0.9)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        density_png = f\"density_png/n{n}_density.png\"\n",
    "        fig.savefig(density_png, dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # ------------------ PDF Table ------------------\n",
    "        density_row = [Image(density_png, width=6.0 * inch, height=2.0 * inch)]\n",
    "\n",
    "        row2 = [Image(f, width=thumb_size[0], height=thumb_size[1]) for f in ch_pngs]\n",
    "        row2.append(Image(merged_png, width=thumb_size[0], height=thumb_size[1]))\n",
    "\n",
    "        data = [\n",
    "            density_row,\n",
    "            row2\n",
    "        ]\n",
    "\n",
    "        table = Table(\n",
    "            data,\n",
    "            colWidths=[1.5 * inch] * 4,     # 4 columns\n",
    "            rowHeights=[2.0 * inch, thumb_size[1]]\n",
    "        )\n",
    "\n",
    "        table.setStyle(TableStyle([\n",
    "            ('SPAN', (0, 0), (3, 0)),  # density spans 4 columns\n",
    "            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ]))\n",
    "\n",
    "        story.append(Paragraph(f\"<b>Nucleus {n} (Z {best_z})</b>\", styles['Heading2']))\n",
    "        story.append(Spacer(1, 0.05 * inch))\n",
    "        story.append(table)\n",
    "        story.append(PageBreak())\n",
    "\n",
    "    doc.build(story)\n",
    "    print(f\"PDF saved to: {output_pdf}\")\n",
    "\n",
    "def double_plateau_hist_equalization_nd(\n",
    "    img: np.ndarray,\n",
    "    num_plateaus: int = 2,\n",
    "    plateau_factor: float = 0.5\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Multi-plateau histogram equalization for 8-bit images or volumes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        Input image/volume, uint8. Can be 2D (H,W) or 3D (Z,H,W) or 3D color (H,W,3).\n",
    "        For 3D, assumes scalar intensities (one channel).\n",
    "    num_plateaus : int\n",
    "        Number of plateau levels (2 = double plateau).\n",
    "    plateau_factor : float\n",
    "        Factor (0–1+) to compute plateau(s) from average count.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : np.ndarray\n",
    "        Equalized image/volume with multi-plateau clipping.\n",
    "    \"\"\"\n",
    "    if img.dtype != np.uint8:\n",
    "        raise ValueError(\"Input must be uint8\")\n",
    "\n",
    "    # 2D grayscale\n",
    "    if img.ndim == 2:\n",
    "        return _mphe_channel(img, num_plateaus, plateau_factor)\n",
    "\n",
    "    # 3D scalar volume (e.g. Z,H,W)\n",
    "    if img.ndim == 3 and img.shape[-1] != 3:\n",
    "        # Flatten to 1D for histogram, then map back\n",
    "        flat = img.ravel()\n",
    "        flat_eq = _mphe_flat(flat, num_plateaus, plateau_factor)\n",
    "        return flat_eq.reshape(img.shape)\n",
    "\n",
    "    # 3D color (H,W,3) image: apply on luminance\n",
    "    if img.ndim == 3 and img.shape[-1] == 3:\n",
    "        ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "        y, cr, cb = cv2.split(ycrcb)\n",
    "        y_eq = _mphe_channel(y, num_plateaus, plateau_factor)\n",
    "        ycrcb_eq = cv2.merge([y_eq, cr, cb])\n",
    "        out = cv2.cvtColor(ycrcb_eq, cv2.COLOR_YCrCb2BGR)\n",
    "        return out\n",
    "\n",
    "    raise ValueError(\"Unsupported input shape\")\n",
    "\n",
    "\n",
    "def _mphe_flat(\n",
    "    flat: np.ndarray,\n",
    "    num_plateaus: int,\n",
    "    plateau_factor: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Multi-plateau HE on a flat uint8 array.\"\"\"\n",
    "    # Compute histogram\n",
    "    hist = np.bincount(flat, minlength=256).astype(np.float64)\n",
    "    total_pixels = flat.size\n",
    "\n",
    "    mean_count = total_pixels / 256.0\n",
    "    base_plateau = plateau_factor * mean_count\n",
    "\n",
    "    plateau_levels = np.linspace(\n",
    "        base_plateau * 0.5,\n",
    "        base_plateau * (0.5 + num_plateaus),\n",
    "        num_plateaus\n",
    "    )\n",
    "\n",
    "    clipped_hist = hist.copy()\n",
    "\n",
    "    for p in plateau_levels:\n",
    "        excess = np.maximum(clipped_hist - p, 0)\n",
    "        clipped_hist = np.minimum(clipped_hist, p)\n",
    "        redistributed = excess.sum() / 256.0\n",
    "        clipped_hist += redistributed\n",
    "\n",
    "    cdf = np.cumsum(clipped_hist)\n",
    "    cdf_norm = cdf / cdf[-1]\n",
    "    lut = np.floor(255 * cdf_norm).astype(np.uint8)\n",
    "\n",
    "    return lut[flat]\n",
    "\n",
    "\n",
    "def _mphe_channel(channel: np.ndarray,\n",
    "                  num_plateaus: int,\n",
    "                  plateau_factor: float) -> np.ndarray:\n",
    "    \"\"\"2D helper using the 1D flat implementation.\"\"\"\n",
    "    flat = channel.ravel()\n",
    "    flat_eq = _mphe_flat(flat, num_plateaus, plateau_factor)\n",
    "    return flat_eq.reshape(channel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acba6cf-3693-44f0-a84e-458fe3eccc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_touching_labels(label_matrix, contact_abs_min=15, contact_rel_min=0.10, \n",
    "                         size_ratio_max=3.0, connectivity=1):\n",
    "    \"\"\"\n",
    "    Merge touching labels selectively: only fragments/splinters, \n",
    "    NOT two large nuclei with small contact.\n",
    "    \"\"\"\n",
    "    if label_matrix.max() == 0:\n",
    "        return label_matrix.copy()\n",
    "\n",
    "    # Precompute volumes\n",
    "    labels, counts = np.unique(label_matrix, return_counts=True)\n",
    "    volumes = dict(zip(labels.tolist(), counts.tolist()))\n",
    "    volumes.pop(0, None)\n",
    "\n",
    "    # Neighbor offsets for connectivity\n",
    "    offsets = []\n",
    "    for dz in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            for dx in [-1, 0, 1]:\n",
    "                if dz == dy == dx == 0:\n",
    "                    continue\n",
    "                if connectivity == 1 and (abs(dx) + abs(dy) + abs(dz) > 1):\n",
    "                    continue\n",
    "                offsets.append((dz, dy, dx))\n",
    "\n",
    "    # Count shared boundary voxels between label pairs\n",
    "    touching_counts = defaultdict(int)\n",
    "    Z, Y, X = label_matrix.shape\n",
    "    for z in range(Z):\n",
    "        for y in range(Y):\n",
    "            for x in range(X):\n",
    "                c = label_matrix[z, y, x]\n",
    "                if c == 0:\n",
    "                    continue\n",
    "                for dz, dy, dx in offsets:\n",
    "                    nz, ny, nx = z + dz, y + dy, x + dx\n",
    "                    if (0 <= nz < Z and 0 <= ny < Y and 0 <= nx < X):\n",
    "                        n = label_matrix[nz, ny, nx]\n",
    "                        if n > 0 and n != c:\n",
    "                            a, b = sorted((c, n))\n",
    "                            touching_counts[(a, b)] += 1\n",
    "\n",
    "    # Union-Find\n",
    "    all_labels = set(volumes.keys())\n",
    "    parent = {label: label for label in all_labels}\n",
    "\n",
    "    def find(u):\n",
    "        while parent[u] != u:\n",
    "            parent[u] = parent[parent[u]]\n",
    "            u = parent[u]\n",
    "        return u\n",
    "\n",
    "    def union(u, v):\n",
    "        pu, pv = find(u), find(v)\n",
    "        if pu != pv:\n",
    "            parent[pu] = pv\n",
    "\n",
    "    # Selective merging\n",
    "    for (u, v), contact in touching_counts.items():\n",
    "        vol_u, vol_v = volumes[u], volumes[v]\n",
    "        vol_min, vol_max = min(vol_u, vol_v), max(vol_u, vol_v)\n",
    "        rel_contact = contact / float(vol_min)\n",
    "        \n",
    "        # Merge only if: large absolute + large relative + similar sizes\n",
    "        if (contact >= contact_abs_min and \n",
    "            rel_contact >= contact_rel_min and \n",
    "            vol_max / vol_min <= size_ratio_max):\n",
    "            union(u, v)\n",
    "\n",
    "    # Remap labels\n",
    "    label_map = {label: find(label) for label in all_labels}\n",
    "    merged = np.zeros_like(label_matrix, dtype=np.int32)\n",
    "    for label, root in label_map.items():\n",
    "        merged[label_matrix == label] = root\n",
    "    merged, _, _ = relabel_sequential(merged)\n",
    "    return merged\n",
    "\n",
    "# REPLACED WATERSHED PIPELINE\n",
    "def watershed_nuclei(im_in, c, nuclei_diameter, r_zZ, r_zY, r_zX):\n",
    "    \"\"\"\n",
    "    Complete watershed + selective merge for nuclei.\n",
    "    \"\"\"\n",
    "    # Distance transform (unchanged)\n",
    "    distance = ndi.distance_transform_edt(im_in[:, :, :, c], \n",
    "                                        sampling=[r_zZ, r_zY, r_zX])\n",
    "    \n",
    "    # IMPROVED peak detection for touching nuclei\n",
    "    radius_X = int((nuclei_diameter / 2.0) / r_zX)\n",
    "    radius_Y = int((nuclei_diameter / 2.0) / r_zY)\n",
    "    radius_Z = int((nuclei_diameter / 2.0) / r_zZ)\n",
    "    \n",
    "    # Smaller footprint + min_distance → splits fused blobs\n",
    "    footprint_small = make_anisotropic_footprint(\n",
    "        int(0.6 * radius_Z), int(0.6 * radius_Y), int(0.6 * radius_X)\n",
    "    )\n",
    "    min_dist_um = nuclei_diameter * 0.75  # 75% diameter minimum separation\n",
    "    min_dist_vox = int(np.min([min_dist_um / r_zZ, min_dist_um / r_zY, min_dist_um / r_zX]))\n",
    "    \n",
    "    coords = peak_local_max(\n",
    "        distance,\n",
    "        footprint=footprint_small,\n",
    "        min_distance=min_dist_vox,  # KEY: forces separate markers\n",
    "        labels=im_in[:, :, :, c].astype(np.int32)\n",
    "    )\n",
    "    \n",
    "    # Markers (unchanged)\n",
    "    mask = np.zeros(distance.shape, dtype=bool)\n",
    "    mask[tuple(coords.T)] = True\n",
    "    markers, _ = ndi.label(mask)\n",
    "    \n",
    "    # Watershed (unchanged)\n",
    "    im_out = markers #watershed(-distance, markers, mask=im_in[:, :, :, c])\n",
    "    \n",
    "    # Size estimate for your other function\n",
    "    size_nuclei = np.pi * 4.0 * (np.mean([radius_X, radius_Y])**3.0) / 3.0\n",
    "    \n",
    "    # SELECTIVE MERGE (replaces your old merge_touching_labels)\n",
    "    # im_out = merge_touching_labels(\n",
    "    #     im_out,\n",
    "    #     contact_abs_min=15,      # tune\n",
    "    #     contact_rel_min=0.10,    # tune  \n",
    "    #     size_ratio_max=3.0,      # protects large nuclei\n",
    "    #     connectivity=1\n",
    "    # )\n",
    "    \n",
    "    # Your existing cleanup (optional)\n",
    "    #im_out = merge_small_touching_labels(im_out, size_nuclei, z_weight=r_zZ/r_zX)\n",
    "    \n",
    "    return im_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eee1c3-7752-4f21-803a-bf592e4dee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "def shrink_to_markers(binary_3d, connectivity=2, max_iter=100,\n",
    "                     min_final_size=9, max_final_cc=2,\n",
    "                     merge_small_touching=False, size_ratio_thresh=0.5):\n",
    "    \"\"\"\n",
    "    Shrink each island until stable and create markers.\n",
    "    Optionally merge small touching marker-islands into larger neighbors.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    marker_image : bool\n",
    "    marker_labels : int\n",
    "    \"\"\"\n",
    "\n",
    "    binary_3d = binary_3d.astype(bool)\n",
    "    cc_labels, n_cc = ndi.label(\n",
    "        binary_3d,\n",
    "        structure=ndi.generate_binary_structure(3, connectivity)\n",
    "    )\n",
    "    marker_image = np.zeros_like(binary_3d, dtype=bool)\n",
    "    selem = ndi.generate_binary_structure(3, connectivity)\n",
    "\n",
    "    # --- shrink step ---\n",
    "    for cc_id in range(1, n_cc + 1):\n",
    "        cc_mask = (cc_labels == cc_id)\n",
    "        current = cc_mask.copy()\n",
    "        it = 0\n",
    "\n",
    "        while np.sum(current) > min_final_size and it < max_iter:\n",
    "            eroded = ndi.binary_erosion(current, structure=selem)\n",
    "\n",
    "            # if erosion kills it completely, keep last state\n",
    "            if not np.any(eroded):\n",
    "                break\n",
    "\n",
    "            # count components after erosion\n",
    "            n_cc_eroded = ndi.label(eroded, structure=selem)[1]\n",
    "            if n_cc_eroded > max_final_cc:\n",
    "                break  # keep pre-split state\n",
    "\n",
    "            current = eroded\n",
    "            it += 1\n",
    "\n",
    "        marker_image |= current\n",
    "\n",
    "    # label marker islands\n",
    "    marker_labels, n_markers = ndi.label(\n",
    "        marker_image,\n",
    "        structure=ndi.generate_binary_structure(3, connectivity)\n",
    "    )\n",
    "    \n",
    "    if not merge_small_touching or n_markers <= 1:\n",
    "        return marker_image, marker_labels\n",
    "\n",
    "    # --- adjacency + size-based merging ---\n",
    "    # compute sizes\n",
    "    labels, counts = np.unique(marker_labels, return_counts=True)\n",
    "    sizes = dict(zip(labels.tolist(), counts.tolist()))\n",
    "    sizes.pop(0, None)  # remove background\n",
    "\n",
    "    Z, Y, X = marker_labels.shape\n",
    "    offsets = []\n",
    "    for dz in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            for dx in [-1, 0, 1]:\n",
    "                if dz == dy == dx == 0:\n",
    "                    continue\n",
    "                # 6-neighborhood if connectivity==1, else denser\n",
    "                if connectivity == 1 and (abs(dx)+abs(dy)+abs(dz) > 1):\n",
    "                    continue\n",
    "                offsets.append((dz, dy, dx))\n",
    "\n",
    "    # build adjacency set\n",
    "    neighbors = defaultdict(set)\n",
    "    for z in range(Z):\n",
    "        for y in range(Y):\n",
    "            for x in range(X):\n",
    "                c = marker_labels[z, y, x]\n",
    "                if c == 0:\n",
    "                    continue\n",
    "                for dz, dy, dx in offsets:\n",
    "                    nz, ny, nx = z+dz, y+dy, x+dx\n",
    "                    if 0 <= nz < Z and 0 <= ny < Y and 0 <= nx < X:\n",
    "                        n = marker_labels[nz, ny, nx]\n",
    "                        if n > 0 and n != c:\n",
    "                            neighbors[c].add(n)\n",
    "\n",
    "    # decide reassignment: each label may be reassigned to one bigger neighbor\n",
    "    new_label = {lab: lab for lab in sizes.keys()}\n",
    "    print(neighbors)\n",
    "    for lab, neighs in neighbors.items():\n",
    "        #print(neighs)\n",
    "        if not neighs:\n",
    "            continue\n",
    "        size_lab = sizes[lab]\n",
    "        # find biggest neighbor\n",
    "        big = max(neighs, key=lambda L: sizes.get(L, 0))\n",
    "        size_big = sizes.get(big, 0)\n",
    "        if size_big <= 0:\n",
    "            continue\n",
    "        # if lab is at least 50% smaller than the biggest neighbor, merge into it\n",
    "        print(size_lab)\n",
    "        print(size_big)\n",
    "        if (size_lab <= size_ratio_thresh * size_big) or (size_lab < 20.0):\n",
    "            new_label[lab] = big\n",
    "        else:\n",
    "            print(size_lab)\n",
    "            print(size_big)\n",
    "\n",
    "    # apply reassignment\n",
    "    relabeled = marker_labels.copy()\n",
    "    for lab, target in new_label.items():\n",
    "        if lab != target:\n",
    "            relabeled[marker_labels == lab] = target\n",
    "\n",
    "    # relabel to consecutive integers\n",
    "    final_labels, _ = ndi.label(relabeled > 0,\n",
    "                                structure=ndi.generate_binary_structure(3, connectivity))\n",
    "\n",
    "    final_markers = final_labels > 0\n",
    "    return final_markers, final_labels\n",
    "\n",
    "def shrink_to_markers_robust(binary_3d, min_marker_size=3, size_ratio_thresh=0.4, **kwargs):\n",
    "    \"\"\"shrink_to_markers + absolute size filter + relaxed connectivity\"\"\"\n",
    "    markers_bin, markers_lab = shrink_to_markers(binary_3d, connectivity=2, **kwargs)\n",
    "    \n",
    "    # absolute size filter\n",
    "    sizes = np.bincount(markers_lab.ravel())[1:]\n",
    "    keep_labels = np.where(sizes >= min_marker_size)[0] + 1\n",
    "    \n",
    "    filtered = np.isin(markers_lab, keep_labels)\n",
    "    final_labels, _ = ndi.label(filtered)\n",
    "    \n",
    "    return filtered, final_labels\n",
    "\n",
    "def remove_small_island_labels(marker_labels, connectivity=1, size_ratio_thresh=0.5):\n",
    "    labels, counts = np.unique(marker_labels, return_counts=True)\n",
    "    sizes = dict(zip(labels.tolist(), counts.tolist()))\n",
    "    sizes.pop(0, None)  # remove background\n",
    "\n",
    "    Z, Y, X = marker_labels.shape\n",
    "    offsets = []\n",
    "    for dz in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            for dx in [-1, 0, 1]:\n",
    "                if dz == dy == dx == 0:\n",
    "                    continue\n",
    "                # 6-neighborhood if connectivity==1, else denser\n",
    "                if connectivity == 1 and (abs(dx)+abs(dy)+abs(dz) > 1):\n",
    "                    continue\n",
    "                offsets.append((dz, dy, dx))\n",
    "\n",
    "    # build adjacency set\n",
    "    neighbors = defaultdict(set)\n",
    "    for z in range(Z):\n",
    "        for y in range(Y):\n",
    "            for x in range(X):\n",
    "                c = marker_labels[z, y, x]\n",
    "                if c == 0:\n",
    "                    continue\n",
    "                for dz, dy, dx in offsets:\n",
    "                    nz, ny, nx = z+dz, y+dy, x+dx\n",
    "                    if 0 <= nz < Z and 0 <= ny < Y and 0 <= nx < X:\n",
    "                        n = marker_labels[nz, ny, nx]\n",
    "                        if n > 0 and n != c:\n",
    "                            neighbors[c].add(n)\n",
    "\n",
    "    # decide reassignment: each label may be reassigned to one bigger neighbor\n",
    "    new_label = {lab: lab for lab in sizes.keys()}\n",
    "    print(neighbors)\n",
    "    for lab, neighs in neighbors.items():\n",
    "        #print(neighs)\n",
    "        if not neighs:\n",
    "            continue\n",
    "        size_lab = sizes[lab]\n",
    "        # find biggest neighbor\n",
    "        big = max(neighs, key=lambda L: sizes.get(L, 0))\n",
    "        size_big = sizes.get(big, 0)\n",
    "        if size_big <= 0:\n",
    "            continue\n",
    "        # if lab is at least 50% smaller than the biggest neighbor, merge into it\n",
    "        print(size_lab)\n",
    "        print(size_big)\n",
    "        if (size_lab <= size_ratio_thresh * size_big) or (size_lab < 20.0):\n",
    "            new_label[lab] = big\n",
    "        else:\n",
    "            print(size_lab)\n",
    "            print(size_big)\n",
    "\n",
    "    # apply reassignment\n",
    "    relabeled = marker_labels.copy()\n",
    "    for lab, target in new_label.items():\n",
    "        if lab != target:\n",
    "            relabeled[marker_labels == lab] = target\n",
    "\n",
    "    # relabel to consecutive integers\n",
    "    final_labels, _ = ndi.label(relabeled > 0,\n",
    "                                structure=ndi.generate_binary_structure(3, connectivity))\n",
    "\n",
    "    final_markers = final_labels > 0\n",
    "    return final_markers, relabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9ed9d-96d7-4068-9b7c-f2ec17a58aa4",
   "metadata": {},
   "source": [
    "# INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7688f7-5b17-498f-86b8-90e4a13226f3",
   "metadata": {},
   "source": [
    "### File upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41837bd-55ba-4b37-affd-bc756542813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TIFF file and extract image data\n",
    "input_file = 'EB-014_M1_ST_BX15043_20x.nd2'\n",
    "big_image=True\n",
    "ROI = [500, 1600, 0, 2000, 30, 80] #XYZ - put 0 to keep the original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff9db6-0cb9-415e-afce-8202c42d9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = AICSImage(input_file)\n",
    "if big_image:\n",
    "    x0, x1, y0, y1, z0, z1 = ROI\n",
    "    if x1==0:\n",
    "        x1 = meta.shape[0]\n",
    "    if y1==0:\n",
    "        y1 = meta.shape[1]\n",
    "    if z1==0:\n",
    "        z1 = meta.shape[2]\n",
    "    # Get lazy dask array in a known order, e.g. \"TCZYX\"\n",
    "    lazy = meta.get_image_dask_data(\"ZYXC\")\n",
    "    sub = lazy[z0:z1, y0:y1, x0:x1, :]\n",
    "    # Actually load this subset into memory\n",
    "    img = sub.compute()\n",
    "    ROI = [0, 0, 0, 0, 0, 0]\n",
    "else:\n",
    "    img = meta.get_image_data(\"XYZ\", T=0) \n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fabebf-7945-48e6-97a8-7683caed6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get physical pixel sizes\n",
    "r_X = meta.physical_pixel_sizes.X #um/px\n",
    "r_Y = meta.physical_pixel_sizes.Y #um/px\n",
    "r_Z = meta.physical_pixel_sizes.Z #um/px\n",
    "print([r_X, r_Y, r_Z])\n",
    "\n",
    "if big_image==False:\n",
    "    imdata=meta.get_image_data()\n",
    "    imtype=imdata.dtype\n",
    "    bdepth=imtype.itemsize*8\n",
    "    print(imtype)\n",
    "\n",
    "with ND2Reader(input_file) as nd2:\n",
    "    print(\"Date:\", nd2.metadata.get(\"date\"))\n",
    "    print(\"Channels:\", nd2.metadata.get(\"channels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47b986-7d7b-4a57-a8ed-0473e4601c40",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c105211-8565-4b07-8add-dec175f71881",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_diameter=10 #um\n",
    "cell_diameter=30 #um\n",
    "\n",
    "cyto_factor=3.0\n",
    "PCM_factor=4.0\n",
    "\n",
    "stain_dict = {\n",
    "    'NUCLEI': ['DAPI', 'DAPI_20x', 'Blue'],\n",
    "    'MACRO': ['F4_80', '488_20x', 'Green'],\n",
    "    'M1': ['iNOS', '568_20x', 'Red'],\n",
    "    'M2': ['CD206', '647_20x', 'White']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4afa3b-4101-4f6a-9632-11933a75c444",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103b005-2497-4954-a829-2884c6bff02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor=0.5\n",
    "zoom_factors = [1.0, 1.0, 1.0] #XYZ\n",
    "zoom_factors = [x * scale_factor for x in zoom_factors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d1a10-4f9e-41ca-9785-ca2bae4302fd",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8fc80-6be8-4ba6-b29f-f630c2648295",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_setup = 'PRO_EB-014b'\n",
    "use_setup = True\n",
    "trig_stardist = False  # Set to True to use StarDist model\n",
    "multilabel=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa8737-3bbf-4ad5-a5af-5e4d20ffb197",
   "metadata": {},
   "source": [
    "## INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fa518-bb33-4a94-92c0-9a9e932f8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_radius=nuclei_diameter*0.5 #um\n",
    "cell_radius=cell_diameter*0.5 #um\n",
    "\n",
    "nuclei_volume=np.ceil(4.0*((nuclei_radius)**3.0)*np.pi/3.0) #um^3\n",
    "cell_volume=np.ceil(4.0*((cell_radius)**3.0)*np.pi/3.0) #um^3\n",
    "\n",
    "x0, x1, y0, y1, z0, z1 = ROI\n",
    "\n",
    "if x1==0:\n",
    "    x1 = img.shape[0]\n",
    "if y1==0:\n",
    "    y1 = img.shape[1]\n",
    "if z1==0:\n",
    "    z1 = img.shape[2]\n",
    "\n",
    "if big_image:\n",
    "    im_original = img.astype('float32')\n",
    "    im_original_ROI = im_original.copy()\n",
    "else:\n",
    "    im_original = meta.get_image_data(\"ZYXC\", S=0, T=0).astype('float32')\n",
    "    im_original_ROI = im_original[z0:z1,y0:y1,x0:x1,:]\n",
    "\n",
    "im_final_stack={'Original image': im_original_ROI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e12c7a-72e0-4050-91e8-0991d92718c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if big_image:\n",
    "    # Ensure `Original image` has axes Z,Y,X,C and squeeze singleton time axis\n",
    "    orig = im_final_stack['Original image']\n",
    "    try:\n",
    "        shape = orig.shape\n",
    "    except Exception:\n",
    "        shape = None\n",
    "    print('Original image shape before fix:', shape)\n",
    "    if shape is not None:\n",
    "        if len(shape) == 5:\n",
    "            # common order Z,Y,X,C,T -> drop T if singleton\n",
    "            if shape[4] == 1:\n",
    "                orig = orig[..., 0]\n",
    "        if len(orig.shape) == 4:\n",
    "            # ensure channels are last: if last axis looks large (likely X), detect small axis as channel\n",
    "            if orig.shape[-1] > 50:\n",
    "                chan_axis = next((i for i, s in enumerate(orig.shape) if s < 50), None)\n",
    "                if chan_axis is not None and chan_axis != 3:\n",
    "                    import numpy as np\n",
    "                    orig = np.moveaxis(orig, chan_axis, -1)\n",
    "    im_final_stack['Original image'] = orig\n",
    "    print('Original image shape after fix:', getattr(orig, 'shape', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24701d78-90c0-4df3-a9ac-0f9098776dc0",
   "metadata": {},
   "source": [
    "### Information about the staining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d0505-c5fb-4b93-b130-254add588d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define staining dictionary and create DataFrame\n",
    "stain_dict = {k.upper(): [item.upper() if isinstance(item, str) else item for item in v] for k, v in stain_dict.items()}\n",
    "stain_df = pd.DataFrame.from_dict(stain_dict, orient='index', columns=['Marker', 'Laser', 'Color'])\n",
    "laser_order=nd2.metadata.get(\"channels\")\n",
    "\n",
    "# Map fluorophore to its order index\n",
    "order_map = {name.strip().upper(): i for i, name in enumerate(laser_order)}\n",
    "stain_df['order'] = stain_df['Laser'].map(order_map)\n",
    "\n",
    "# Sort by that and drop helper column\n",
    "stain_df = stain_df.sort_values('order').drop(columns='order')\n",
    "\n",
    "stain_df.index.name = 'Condition'\n",
    "\n",
    "if 'NUCLEI' not in stain_df.index:\n",
    "    print('No nuclei condition!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d257a-9efb-44c3-8228-2be4978e9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize each channel using napari\n",
    "im_in=im_final_stack['Original image'].copy()\n",
    "\n",
    "viewer_0 = napari.Viewer()\n",
    "for c, c_name in enumerate(stain_df['Marker']):\n",
    "    #im_in = meta.get_image_data(\"ZYX\", C=c, S=0, T=0).astype('float32')\n",
    "    im_channel = im_in[:,:,:,c]\n",
    "\n",
    "    # Stretch to [0, 255]\n",
    "    im_8b = ((im_channel - im_channel.min()) / (im_channel.max() - im_channel.min()) * 255).clip(0, 255).astype('uint8')\n",
    "    \n",
    "    viewer_0.add_image(im_8b, name=f\"{stain_df.index[c]} ({c_name})\", \n",
    "                        colormap=stain_df['Color'][c], blending='additive', scale=[r_Z,r_Y,r_X])\n",
    "\n",
    "    viewer_0.scale_bar.visible = True\n",
    "    viewer_0.scale_bar.unit = 'um'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63bd45-32c7-45be-8c8e-d1644df8e94c",
   "metadata": {},
   "source": [
    "### Acquisition processing setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2d9c9-3a3b-4f03-ab0d-85d806558cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for acquisition and contrast/gamma settings\n",
    "im_in=im_final_stack['Original image'].copy()\n",
    "\n",
    "stain_df = stain_df.reset_index(drop=False)\n",
    "stain_initial_df = stain_df.copy()\n",
    "stain_initial_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "stain_initial_df[['Cont_min', 'Cont_max', 'Gamma']] = [0, 255, 1]\n",
    "stain_complete_df=stain_initial_df.copy()\n",
    "\n",
    "setup_path = f\"{name_setup}_setup.csv\"\n",
    "if use_setup and os.path.exists(setup_path):\n",
    "    stain_setup_df = pd.read_csv(setup_path)\n",
    "    stain_setup_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "    for idx in stain_complete_df.index:\n",
    "        if idx in stain_setup_df.index:\n",
    "            stain_complete_df.loc[idx] = stain_setup_df.loc[idx]\n",
    "            stain_complete_df['Color'] = stain_initial_df['Color']\n",
    "        else:\n",
    "            use_setup = False\n",
    "\n",
    "if not use_setup or not os.path.exists(setup_path):\n",
    "    stain_complete_df=stain_initial_df.copy()\n",
    "    settings.application.ipy_interactive = False\n",
    "    viewer_1 = napari.Viewer()\n",
    "    for c, idx in enumerate(stain_complete_df.index):\n",
    "        im_channel = im_in[:,:,:,c]\n",
    "        im_channel = ((im_channel - im_channel.min()) / (im_channel.max() - im_channel.min()) * 255).clip(0, 255).astype('uint8')\n",
    "        viewer_1.add_image(im_channel, name=f\"{idx[0]} ({idx[1]})\", colormap=stain_initial_df.loc[idx]['Color'], blending='additive')\n",
    "    napari.run()\n",
    "    image_layers = [layer for layer in viewer_1.layers if isinstance(layer, napari.layers.Image)]\n",
    "    contrast_limits = {layer.name: layer.contrast_limits for layer in image_layers}\n",
    "    gamma_val = {layer.name: layer.gamma for layer in image_layers}\n",
    "    stain_complete_df.sort_index(inplace=True)\n",
    "    for c, idx in enumerate(stain_complete_df.index):\n",
    "        name = f\"{idx[0]} ({idx[1]})\"\n",
    "        stain_complete_df.loc[idx, 'Cont_min'] = int(contrast_limits[name][0])\n",
    "        stain_complete_df.loc[idx, 'Cont_max'] = int(contrast_limits[name][1])\n",
    "        stain_complete_df.loc[idx, 'Gamma'] = gamma_val[name]\n",
    "    if os.path.exists(setup_path):\n",
    "        stain_setup_df = pd.read_csv(setup_path)\n",
    "        stain_setup_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "        for idx in stain_complete_df.index:\n",
    "            stain_setup_df.loc[idx] = stain_complete_df.loc[idx]\n",
    "    else:\n",
    "        stain_setup_df = stain_complete_df.copy()\n",
    "    stain_csv_setup_df = stain_setup_df.reset_index().sort_values(by='Condition')\n",
    "    stain_csv_setup_df = stain_csv_setup_df[['Condition', 'Marker', 'Laser', 'Cont_min', 'Cont_max', 'Gamma']]\n",
    "    stain_csv_setup_df.to_csv(setup_path, index=False)\n",
    "\n",
    "stain_df = stain_df.set_index('Condition')\n",
    "stain_complete_df = stain_complete_df.reset_index().set_index('Condition')\n",
    "stain_complete_df = stain_complete_df.loc[stain_df.index]\n",
    "stain_complete_df = stain_complete_df[['Marker', 'Laser', 'Color', 'Cont_min', 'Cont_max', 'Gamma']]\n",
    "original_stain_complete_df=stain_complete_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c459fc7-429e-4592-b5eb-9cedb37c8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display stain settings DataFrame\n",
    "stain_complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d61176-9e49-4c94-8f04-b4fa2a16219f",
   "metadata": {},
   "source": [
    "## IMAGE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679eb17-77b9-4454-b807-e2a074f239d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize image data for all channels\n",
    "im_in=im_final_stack['Original image'].copy()\n",
    "im_out=im_in.copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_ori = im_in[:, :, :, c].copy()\n",
    "    im_out[:, :, :, c] = ((im_ori - im_ori.min()) / (im_ori.max() - im_ori.min()) * 255).clip(0, 255).astype('uint8')\n",
    "\n",
    "im_final_stack['Normalized image']=im_out.copy()\n",
    "\n",
    "# Plot histogram for each channel\n",
    "hist_plot(im_final_stack['Normalized image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1863a4-8080-41ed-bec3-1c0aa0a13686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt resolution to isotropic\n",
    "im_in=im_final_stack['Normalized image'].copy()\n",
    "\n",
    "im_out = np.zeros((round(np.shape(im_in)[0] * (zoom_factors[0])),round(np.shape(im_in)[1] * (zoom_factors[1])),round(np.shape(im_in)[2] * (zoom_factors[2])),np.shape(im_in)[3]))\n",
    "\n",
    "# Compute zoom factors to get isotropic spacing (same as Y and X)\n",
    "r_zX = meta.physical_pixel_sizes.X/zoom_factors[0]\n",
    "r_zY = meta.physical_pixel_sizes.Y/zoom_factors[1]\n",
    "r_zZ = meta.physical_pixel_sizes.Z/zoom_factors[2]\n",
    "\n",
    "# Resample image to isotropic spacing\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = zoom(im_in[:, :, :, c], zoom=zoom_factors, order=1)\n",
    "    im_out[:, :, :, c] = im_out[:, :, :, c] - np.min(im_out[:, :, :, c])\n",
    "\n",
    "    im_out[:, :, :, c] = ((im_out[:, :, :, c] - im_out[:, :, :, c].min()) / (im_out[:, :, :, c].max() - im_out[:, :, :, c].min()) * 255).clip(0, 255).astype('uint8')\n",
    "\n",
    "im_final_stack['Zoomed image']=im_out.copy()\n",
    "hist_plot(im_final_stack['Zoomed image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92171d9e-4dde-4f95-ba32-07d8cd4940e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise removal using median filter\n",
    "im_in = im_final_stack['Zoomed image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = filters.median(im_in[:, :, :, c])\n",
    "im_final_stack['Denoised image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Denoised image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216ae01-cee5-4d8a-8e9b-14069a0fc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast and gamma adjustment for each channel\n",
    "im_in = im_final_stack['Denoised image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    idx = stain_complete_df.index[c]\n",
    "    im_out[:, :, :, c] = napari_contrast_gamma_uint8(im_in[:, :, :, c], (stain_complete_df.loc[idx, 'Cont_min'], stain_complete_df.loc[idx, 'Cont_max']), stain_complete_df.loc[idx, 'Gamma'])\n",
    "    \n",
    "im_final_stack['Adjusted image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Adjusted image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13246cee-6f45-4fd9-b95f-f9cc8df4865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filter for smoothing\n",
    "im_in = im_final_stack['Adjusted image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = filters.gaussian(im_in[:, :, :, c], 0.5, preserve_range=True)\n",
    "\n",
    "im_final_stack['Filtered image'] = im_out.astype('uint8')\n",
    "hist_plot(im_final_stack['Filtered image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d119a-a4e3-41ad-8de5-b91c110d3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export histograms\n",
    "output_path=Path(input_file).stem + '_histograms.xlsx'\n",
    "im_in = im_final_stack['Adjusted image'].copy()\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "    for c in range(im_in.shape[3]):\n",
    "        # Example input: 3D array (e.g. image stack)\n",
    "        im3d = im_in[:, :, :, c].copy()\n",
    "\n",
    "        # Compute histogram\n",
    "        values, counts = np.unique(im3d.astype('int'), return_counts=True)\n",
    "        hist = np.zeros(256, dtype=int)\n",
    "        hist[values] = counts\n",
    "\n",
    "        # Calculate totals, percentages, and cumulative values\n",
    "        total = hist.sum()\n",
    "        percentage = (hist / total) * 100\n",
    "        cumulative = np.cumsum(hist)\n",
    "        cumulative_percentage = np.cumsum(percentage)\n",
    "\n",
    "        # Build DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            \"Pixel_Value\": np.arange(256),\n",
    "            \"Count\": hist,\n",
    "            \"Percentage\": percentage,\n",
    "            \"Cumulative_Count\": cumulative,\n",
    "            \"Cumulative_Percentage\": cumulative_percentage\n",
    "        })\n",
    "\n",
    "        idx = stain_complete_df.index[c]\n",
    "        marker = stain_complete_df.loc[idx, 'Marker']\n",
    "\n",
    "        # Write each to a different sheet\n",
    "        df.to_excel(writer, sheet_name=marker, index=False)\n",
    "    \n",
    "print(f\"Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b7708-b305-4442-82d8-56378f7e31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Thresholding using Otsu, Sauvola, statistical background, gain filtering\n",
    "# im_in = im_final_stack[\"Filtered image\"].copy()\n",
    "# im_out = im_in.copy()\n",
    "\n",
    "# for c in range(im_in.shape[3]):\n",
    "#     img = sitk.GetImageFromArray(im_in[:, :, :, c])\n",
    "\n",
    "#     # Stretch for Otsu\n",
    "#     rescaler = sitk.RescaleIntensityImageFilter()\n",
    "#     rescaler.SetOutputMinimum(0)\n",
    "#     rescaler.SetOutputMaximum(255)\n",
    "#     stretched = rescaler.Execute(img)\n",
    "\n",
    "#     # Otsu thresholds\n",
    "#     th_filter = sitk.OtsuThresholdImageFilter()\n",
    "#     _ = th_filter.Execute(stretched)\n",
    "#     otsu_value = th_filter.GetThreshold()\n",
    "\n",
    "#     _ = th_filter.Execute(img)\n",
    "#     otsu_value2 = th_filter.GetThreshold()\n",
    "\n",
    "#     # Sizes\n",
    "#     nuclei_size = int(nuclei_diameter * scale_factor / (np.mean([r_X, r_Y])))\n",
    "#     cell_size = int(cell_diameter * scale_factor / (np.mean([r_X, r_Y])))\n",
    "\n",
    "#     if stain_complete_df.index[c] == \"NUCLEI\":\n",
    "#         window_size = 2 * nuclei_size + 1\n",
    "#     else:\n",
    "#         window_size = 2 * cell_size + 1\n",
    "\n",
    "#     # Convert to array\n",
    "#     arr = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "\n",
    "#     # Sauvola threshold map\n",
    "#     sauvola_value = threshold_sauvola(arr, window_size=int(window_size))\n",
    "\n",
    "#     # Statistical background threshold\n",
    "#     hist, bins = np.histogram(arr, bins=256, range=(0, arr.max()))\n",
    "#     mode_bin = bins[np.argmax(hist)]\n",
    "\n",
    "#     bg_mask = (arr >= mode_bin - 5) & (arr <= mode_bin + 5)\n",
    "#     bg_vals = arr[bg_mask]\n",
    "#     if bg_vals.size < window_size:\n",
    "#         bg_vals = arr\n",
    "\n",
    "#     bg_mean = bg_vals.mean()\n",
    "#     bg_std = bg_vals.std() + 1e-6\n",
    "#     z = 3.0\n",
    "#     statistical_thr = bg_mean + z * bg_std\n",
    "\n",
    "#     print(bg_mean)\n",
    "\n",
    "#     # Final combined threshold map\n",
    "#     final_thr = (\n",
    "#         0.75 * sauvola_value +\n",
    "#         0.15 * statistical_thr +\n",
    "#         0.10 * otsu_value2\n",
    "#     )\n",
    "\n",
    "#     # Extra improvement: intensity gain check\n",
    "#     # Only keep pixels that rise at least X times above background mean\n",
    "#     gain = arr / (bg_mean + 1e-6)\n",
    "#     mask_gain = gain > 10.0    # adjust if needed\n",
    "\n",
    "#     # Apply threshold\n",
    "#     arrayseg = (arr > final_thr) & mask_gain\n",
    "\n",
    "#     # Remove small islands\n",
    "#     min_size = np.ceil(0.8 * np.pi * ((nuclei_size / 2) ** 2))\n",
    "#     im_out[:, :, :, c] = remove_small_islands(arrayseg, min_size)\n",
    "\n",
    "# im_final_stack[\"Threshold image\"] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389400c6-b361-4689-8140-72c48146e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization, supporting thresholding\n",
    "im_in = im_final_stack['Filtered image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = double_plateau_hist_equalization_nd(im_in[:, :, :, c].astype('uint8'), num_plateaus=2, plateau_factor=0.7)\n",
    "\n",
    "im_final_stack['Equalized image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Equalized image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258aaf4f-0507-4ab1-9fc6-e9d47c6d9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding using Otsu, Sauvola, statistical background, gain filtering\n",
    "im_in = im_final_stack[\"Equalized image\"].copy()\n",
    "im_out = im_in.copy()\n",
    "\n",
    "# Sizes\n",
    "nuclei_size = int(nuclei_diameter / (np.mean([r_zX, r_zY])))\n",
    "cell_size = int(cell_diameter / (np.mean([r_zX, r_zY])))\n",
    "\n",
    "for c in range(im_in.shape[3]):\n",
    "    img = sitk.GetImageFromArray(im_in[:, :, :, c])\n",
    "\n",
    "    # Stretch for Otsu\n",
    "    rescaler = sitk.RescaleIntensityImageFilter()\n",
    "    rescaler.SetOutputMinimum(0)\n",
    "    rescaler.SetOutputMaximum(255)\n",
    "    stretched = rescaler.Execute(img)\n",
    "\n",
    "\n",
    "    # Otsu thresholds\n",
    "    th_filter = sitk.OtsuThresholdImageFilter()\n",
    "    _ = th_filter.Execute(stretched)\n",
    "    otsu_value = th_filter.GetThreshold()\n",
    "\n",
    "    _ = th_filter.Execute(img)\n",
    "    otsu_value2 = th_filter.GetThreshold()\n",
    "\n",
    "    if stain_complete_df.index[c] == \"NUCLEI\":\n",
    "        window_size = 1 * nuclei_size #+ 1\n",
    "    else:\n",
    "        window_size = 4 * cell_size + 1\n",
    "\n",
    "    # Convert to array\n",
    "    arr = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "\n",
    "    # Sauvola threshold map\n",
    "    sauvola_value = threshold_sauvola(arr, window_size=int(window_size))\n",
    "\n",
    "    # -------- GLOBAL statistical background, excluding zeros --------\n",
    "    non_zero = arr[arr > 0]\n",
    "\n",
    "    if non_zero.size > 0:\n",
    "        hist, bins = np.histogram(non_zero, bins=256, range=(0, non_zero.max()))\n",
    "        mode_bin = bins[np.argmax(hist)]\n",
    "\n",
    "        bg_mask = (arr >= mode_bin - 5) & (arr <= mode_bin + 5) & (arr > 0)\n",
    "        bg_vals = arr[bg_mask]\n",
    "\n",
    "        if bg_vals.size < 50:\n",
    "            p10 = np.percentile(non_zero, 10)\n",
    "            bg_vals = non_zero[non_zero <= p10]\n",
    "    else:\n",
    "        bg_vals = arr\n",
    "\n",
    "    bg_mean = bg_vals.mean()\n",
    "    bg_std = bg_vals.std() + 1e-6\n",
    "\n",
    "    bg_mean_z = arr.mean()\n",
    "    bg_std_z = arr.std() + 1e-6\n",
    "    z = 3.0\n",
    "    statistical_thr = bg_mean_z + z * bg_std_z\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "\n",
    "    # 1) Soften Sauvola if it is too aggressive for large/bright cells\n",
    "    # Clip Sauvola so it cannot exceed a few std above the global (zero‑including) mean\n",
    "    max_sauvola = bg_mean_z + 2.0 * bg_std_z\n",
    "    sauvola_clipped = np.minimum(sauvola_value, max_sauvola)\n",
    "\n",
    "    # Final combined threshold map (slightly less Sauvola weight)\n",
    "    final_thr = (\n",
    "        0.60 * sauvola_clipped +\n",
    "        0.25 * statistical_thr +\n",
    "        0.15 * otsu_value2\n",
    "    )\n",
    "\n",
    "    # Extra improvement: intensity gain check (global, using non-zero-based bg_mean)\n",
    "    gain = arr / (bg_mean + 1e-6)\n",
    "    mask_gain = gain > 6.0    # tune 2–5 depending on SNR\n",
    "\n",
    "    # 2) Rescue pixels: strong gain but slightly under final_thr\n",
    "    primary = (arr > final_thr) & mask_gain\n",
    "    rescue = (gain > 9.0) & (arr > statistical_thr)   # gain threshold > primary, to keep it conservative\n",
    "\n",
    "    arrayseg = primary | rescue\n",
    "\n",
    "    if stain_complete_df.index[c] != 'NUCLEI':\n",
    "        min_size = np.ceil(0.8 * np.pi * ((nuclei_size / 2) ** 2))\n",
    "    else:\n",
    "        min_size= np.ceil(0.4 * np.pi * ((nuclei_size / 2) ** 2))\n",
    "\n",
    "    # Remove small islands\n",
    "    \n",
    "    im_out[:, :, :, c] = remove_small_islands(arrayseg, min_size)\n",
    "\n",
    "im_final_stack[\"Threshold image\"] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22fad8-8e61-4701-be76-e79d6f67c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of nuclei using watershed or StarDist\n",
    "trig_stardist=False\n",
    "if 'NUCLEI' in stain_df.index:\n",
    "    im_in=im_final_stack['Threshold image'].copy()\n",
    "    \n",
    "    for c in range(im_in.shape[3]):\n",
    "        if stain_complete_df.index[c] == 'NUCLEI':\n",
    "            if trig_stardist:\n",
    "                im_in=im_final_stack['Equalized image'].copy()\n",
    "                transl=stardist3d_from_2d(img_3d=im_in[:,:,:,c],nucleus_radius=nuclei_diameter/2.0,voxel_size=(r_zZ, r_zY, r_zX))\n",
    "                im_mask = transl>0\n",
    "                im_mask = morphology.binary_erosion(im_mask, footprint=np.ones((2, 2, 2))).astype(im_mask.dtype)\n",
    "                im_out,num = label((transl * im_mask)>0)\n",
    "            else:\n",
    "                # distance = ndi.distance_transform_edt(im_in[:, :, :, c],sampling=[r_zZ,r_zY,r_zX])\n",
    "                # radius_X = int((nuclei_diameter / 2.0) / r_zX)\n",
    "                # radius_Y = int((nuclei_diameter / 2.0) / r_zY)\n",
    "                # radius_Z = int((nuclei_diameter / 2.0) / r_zZ)\n",
    "                # coords = peak_local_max(distance, footprint=make_anisotropic_footprint(radius_Z, radius_Y, radius_X), labels=im_in[:, :, :, c].astype(np.int32))\n",
    "                # mask = np.zeros(distance.shape, dtype=bool)\n",
    "                # mask[tuple(coords.T)] = True\n",
    "                # markers, _ = ndi.label(mask)\n",
    "                # im_out = watershed(-distance, markers, mask=im_in[:, :, :, c])\n",
    "                # #im_out = watershed_nuclei(im_in, c, nuclei_diameter, r_zZ, r_zY, r_zX)\n",
    "                # #im_out = merge_touching_labels(im_out)\n",
    "                # size_nuclei=np.pi*4.0*(np.mean([radius_X,radius_Y])**3.0)/3.0\n",
    "                # #print(size_nuclei)\n",
    "                # #im_out=merge_small_touching_labels(im_out,size_nuclei,z_weight=r_zZ/r_zX)\n",
    "                # im_out = merge_touching_labels(|\n",
    "                #     im_out,\n",
    "                #     contact_abs_min=10,      # tune for your voxel size\n",
    "                #     contact_rel_min=0.25,    # tune for your nuclei size\n",
    "                #     connectivity=3           # or 2/3 if you want more permissive touching\n",
    "                # )\n",
    "                binary_mask = im_in[:, :, :, c].copy()\n",
    "                _, true_markers = shrink_to_markers_robust(binary_mask)\n",
    "    \n",
    "                distance = ndi.distance_transform_edt(binary_mask, sampling=[r_zZ, r_zY, r_zX])\n",
    "                im_out = watershed(-distance, true_markers, mask=binary_mask)\n",
    "                _,im_out = remove_small_island_labels(im_out, connectivity=1, size_ratio_thresh=0.5)\n",
    "                \n",
    "            im_segmentation_stack={'Nuclei': im_out}\n",
    "            \n",
    "            cm_rand = np.random.rand(int(np.max(im_segmentation_stack['Nuclei'])), 3)\n",
    "            cm_rand[0, :] = [0.0, 0.0, 0.0]\n",
    "            colormaps_rand = Colormap(cm_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b740f045-770f-4c81-99c1-c96e4ab0134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of cytoplasm\n",
    "im_in=im_final_stack['Threshold image'].copy()\n",
    "\n",
    "if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "    im_out = np.zeros_like(im_in[:,:,:,0], dtype=np.int32)\n",
    "    \n",
    "    for c in range(im_in.shape[3]):\n",
    "        if stain_df.index[c] == 'CYTOPLASM':\n",
    "            distance = ndi.distance_transform_edt(im_in[:, :, :, c],sampling=[r_zZ,r_zY,r_zX])\n",
    "            radius_X = int((nuclei_diameter / 2.0) / r_zX)\n",
    "            radius_Y = int((nuclei_diameter / 2.0) / r_zY)\n",
    "            radius_Z = int((nuclei_diameter / 2.0) / r_zZ)\n",
    "            coords = peak_local_max(distance, footprint=make_anisotropic_footprint(radius_Z, radius_Y, radius_X), labels=im_in[:, :, :, c].astype(np.int32))\n",
    "            mask = np.zeros(distance.shape, dtype=bool)\n",
    "            mask[tuple(coords.T)] = True\n",
    "            markers, _ = label(mask)\n",
    "            im_out = watershed(-distance, im_segmentation_stack['Nuclei'], mask=im_in[:, :, :, c])\n",
    "    \n",
    "    if 'CYTOPLASM' not in stain_df.index:\n",
    "        im_out=grow_labels(im_segmentation_stack['Nuclei'], cyto_factor)\n",
    "        #stain_df.loc['CYTOPLASM']=['', '', '']\n",
    "        stain_complete_df.loc['CYTOPLASM']=['', '', '', '', '', '']\n",
    "        \n",
    "    im_segmentation_stack['Cytoplasm'] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b6ffa5-b9c9-4b3a-8a99-468b3fee2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of the pericellular matrix (PCM)\n",
    "im_in=im_final_stack['Threshold image'].copy()\n",
    "\n",
    "if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "    im_out = np.zeros_like(im_in[:,:,:,0], dtype=np.int32)\n",
    "    \n",
    "    im_out=grow_labels(im_segmentation_stack['Nuclei'], PCM_factor)\n",
    "    im_out=im_out-im_segmentation_stack['Cytoplasm']\n",
    "        \n",
    "    im_segmentation_stack['PCM'] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc09a6-7acd-4e89-94ef-341b69728685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign segmented nuclei labels to other channels (cell assignment)\n",
    "im_in=im_final_stack['Threshold image'].copy()\n",
    "\n",
    "if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "    for c in range(im_in.shape[3]):\n",
    "        if (stain_df.index[c] != 'NUCLEI') & (stain_df.index[c] != 'CYTOPLASM') & (stain_df.index[c] != 'PCM'):\n",
    "            im_segmentation_stack[stain_df.index[c]] = im_in[:, :, :, c] * (im_segmentation_stack['Cytoplasm'] + im_segmentation_stack['PCM'])\n",
    "            im_segmentation_stack[stain_df.index[c] + '_cyto'] = im_in[:, :, :, c] * (im_segmentation_stack['Cytoplasm'])\n",
    "            im_segmentation_stack[stain_df.index[c] + '_PCM'] = im_in[:, :, :, c] * (im_segmentation_stack['PCM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657ebe4-8d4a-49c8-bb13-962b669d83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate aggregates\n",
    "# if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "#     im_out,num_aggregates=label(grow_labels(im_segmentation_stack['Cytoplasm'],2.0)>0)\n",
    "#     im_segmentation_stack['Aggregates']=im_out*(im_segmentation_stack['Cytoplasm']>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cff7e-fe98-48d5-b32a-bbe0fabd7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original, denoised, filtered, corrected, thresholded, assigned, and segmented images\n",
    "viewer_0 = napari.Viewer()\n",
    "scale_zoom=(r_zZ, r_zY, r_zX)\n",
    "\n",
    "for c in range(im_in.shape[3]):\n",
    "    idx = stain_complete_df.index[c]\n",
    "    marker = stain_complete_df.loc[idx, 'Marker']\n",
    "    color = stain_complete_df['Color'].iloc[c]\n",
    "    #viewer_0.add_image(im_final_stack['Normalized image'], name=f'NORMALIZED {idx} ({marker})', colormap=color, blending='additive')\n",
    "    viewer_0.add_image(im_final_stack['Original image'][:, :, :, c], name=f'ORIGINAL {idx} ({marker})', colormap=color, blending='additive', scale=[r_Z, r_Y, r_X])\n",
    "    viewer_0.add_image(im_final_stack['Zoomed image'][:, :, :, c], name=f'ZOOMED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Denoised image'][:, :, :, c], name=f'DENOISED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Adjusted image'][:, :, :, c], name=f'CORRECTED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Filtered image'][:, :, :, c], name=f'FILTERED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Equalized image'][:, :, :, c], name=f'EQ {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Threshold image'][:, :, :, c].astype('uint8'), name=f'THRESHOLD {idx} ({marker})', contrast_limits=[0, 1], colormap=color, blending='additive', scale=scale_zoom)    \n",
    "    if stain_complete_df.index[c] == 'NUCLEI':\n",
    "        viewer_0.add_labels(im_segmentation_stack['Nuclei'].astype('uint8'), name=f'{idx} ({marker})', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "viewer_0.scale_bar.visible = True\n",
    "viewer_0.scale_bar.unit = 'um'\n",
    "\n",
    "if ('NUCLEI' in stain_complete_df.index)|('CYTOPLASM' in stain_complete_df.index):\n",
    "    viewer_1 = napari.Viewer()\n",
    "\n",
    "    im_in=im_final_stack['Threshold image'].copy()\n",
    "    \n",
    "    for c in range(len(stain_complete_df.index)):\n",
    "        idx = stain_complete_df.index[c]\n",
    "        marker = stain_complete_df.loc[idx, 'Marker']\n",
    "        if stain_complete_df.index[c] == 'NUCLEI':\n",
    "            viewer_1.add_labels(im_segmentation_stack['Nuclei'].astype('uint8'), name=f'{idx} ({marker})', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "        if stain_complete_df.index[c] == 'CYTOPLASM':\n",
    "            viewer_1.add_labels(im_segmentation_stack['Cytoplasm'].astype('uint8'), blending='additive', name=f'{idx} ({marker})', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "            viewer_1.add_labels(im_segmentation_stack['PCM'].astype('uint8'), name=f'PCM', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "            #viewer_1.add_labels(im_segmentation_stack['Aggregates'].astype('uint8'), name=f'AGGREGTES', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_aggregates)], blending='additive')\n",
    "        if (stain_complete_df.index[c] != 'NUCLEI') & (stain_complete_df.index[c] != 'CYTOPLASM') & (stain_complete_df.index[c] != 'PCM'):\n",
    "            viewer_1.add_labels(im_segmentation_stack[stain_df.index[c]].astype('uint8'), name=f'{idx} ({marker})', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "    viewer_1.scale_bar.visible = True\n",
    "    viewer_1.scale_bar.unit = 'um'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aab820-7f42-4903-8132-d83edc9479d4",
   "metadata": {},
   "source": [
    "## QUANTIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025d799-05f4-4b3a-adcd-3bec0a42eb5e",
   "metadata": {},
   "source": [
    "# 6. Quantification and Analysis\n",
    "\n",
    "This section quantifies nuclei and cell properties, computes statistics, and visualizes distributions. Results are exported for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3368afcc-5721-4785-82d8-c99433b3ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "\n",
    "r_xyz = (r_zX, r_zY, r_zZ)\n",
    "zooms = zoom_factors\n",
    "nuc_positions, nuc_sizes, cyto_positions, cyto_sizes = compute_nuclei_cytoplasm_stats(im_segmentation_stack, r_xyz, zooms)\n",
    "\n",
    "c_nuc = None\n",
    "c_cyto = None\n",
    "\n",
    "if 'NUCLEI' in stain_complete_df.index:\n",
    "    c_nuc = stain_complete_df.index.get_loc('NUCLEI')\n",
    "if 'CYTOPLASM' in stain_complete_df.index:\n",
    "    c_cyto = stain_complete_df.index.get_loc('CYTOPLASM')\n",
    "\n",
    "if c_nuc is not None:\n",
    "    nuc_marker = stain_complete_df['Marker'][c_nuc]\n",
    "    labels_dict[nuc_marker] = [\n",
    "        stain_complete_df.index[c_nuc],\n",
    "        stain_complete_df['Laser'][c_nuc],\n",
    "        stain_complete_df['Color'][c_nuc],\n",
    "        int(np.max(im_segmentation_stack['Nuclei'])),\n",
    "        (),  # Shared labels placeholder\n",
    "        tuple(nuc_positions),\n",
    "        (),\n",
    "        tuple(nuc_sizes),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        ()\n",
    "    ]\n",
    "\n",
    "if c_cyto is not None:\n",
    "    cyto_marker = stain_complete_df['Marker'][c_cyto]\n",
    "    labels_dict[cyto_marker] = [\n",
    "        stain_complete_df.index[c_cyto],\n",
    "        stain_complete_df['Laser'][c_cyto],\n",
    "        stain_complete_df['Color'][c_cyto],\n",
    "        int(np.max(im_segmentation_stack['Cytoplasm'])),\n",
    "        (),\n",
    "        (),\n",
    "        tuple(cyto_positions),\n",
    "        (),\n",
    "        tuple(cyto_sizes),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        ()\n",
    "    ]\n",
    "\n",
    "filtered_img = im_final_stack['Filtered image']\n",
    "num_channels = filtered_img.shape[3]\n",
    "\n",
    "for c in range(num_channels):\n",
    "    condition = stain_complete_df.index[c]\n",
    "    if condition in ['NUCLEI', 'CYTOPLASM', 'PCM']:\n",
    "        continue\n",
    "    marker = stain_complete_df['Marker'][c]\n",
    "\n",
    "    shared_labels, m_sizes, m_avg, m_std, m_cyto_sizes, m_cyto_avg, m_cyto_std, m_pcm_sizes, m_pcm_avg, m_pcm_std = compute_marker_stats_for_marker(c, im_segmentation_stack, filtered_img, r_xyz, zooms)\n",
    "\n",
    "    labels_dict[marker] = [\n",
    "        condition,\n",
    "        stain_complete_df['Laser'][c],\n",
    "        stain_complete_df['Color'][c],\n",
    "        len(shared_labels),\n",
    "        tuple(sorted(shared_labels)),\n",
    "        tuple(nuc_positions[i-1] for i in shared_labels) if len(shared_labels)>0 else (),\n",
    "        tuple(cyto_positions[i-1] for i in shared_labels) if len(shared_labels)>0 else (),\n",
    "        tuple(nuc_sizes[i-1] for i in shared_labels) if len(shared_labels)>0 else (),\n",
    "        tuple(cyto_sizes[i-1] for i in shared_labels) if len(shared_labels)>0 else (),\n",
    "        tuple(m_sizes),\n",
    "        tuple(m_avg),\n",
    "        tuple(m_std),\n",
    "        tuple(m_cyto_sizes),\n",
    "        tuple(m_cyto_avg),\n",
    "        tuple(m_cyto_std),\n",
    "        tuple(m_pcm_sizes),\n",
    "        tuple(m_pcm_avg),\n",
    "        tuple(m_pcm_std)\n",
    "    ]\n",
    "\n",
    "    # list_ints = [np.round(x) for x in list_m]\n",
    "    # hist, _ = np.histogram(np.concatenate(list_ints), 256, [0, 256])\n",
    "    # axs[c].hist(np.concatenate(list_ints), 256, [0, 256], color=stain_complete_df['Color'][c] if stain_complete_df['Color'][c] != 'WHITE' else 'GRAY')\n",
    "    # axs[c].set_xlim([0, 256])\n",
    "    # axs[c].legend(('cdf', 'histogram'), loc='upper left')\n",
    "    # axs[c].set_title(stain_complete_df.index[c])\n",
    "    \n",
    "\n",
    "if multilabel:\n",
    "    max_combo_size = min(3, max(2, num_channels - 1))\n",
    "    non_nuc_channels = [i for i in range(num_channels) if stain_complete_df.index[i] not in ['NUCLEI', 'CYTOPLASM', 'PCM']]\n",
    "    \n",
    "    marker_index_to_shared = {}\n",
    "    for c in non_nuc_channels:\n",
    "        mname = stain_complete_df['Marker'][c]\n",
    "        marker_index_to_shared[c] = set(labels_dict[mname][4]) if mname in labels_dict else set()\n",
    "    \n",
    "    for k in range(2, max_combo_size + 1):\n",
    "        for comb in combinations(non_nuc_channels, k):\n",
    "            combo_markers = tuple(stain_complete_df['Marker'][i] for i in comb)\n",
    "            # intersect shared label sets\n",
    "            sets = [marker_index_to_shared[i] for i in comb]\n",
    "            if len(sets) == 0:\n",
    "                continue\n",
    "            combo_labels = set.intersection(*sets)\n",
    "            combo_labels = sorted(combo_labels)\n",
    "            if len(combo_labels) == 0:\n",
    "                continue\n",
    "            # build entry similar to single markers\n",
    "            labels_dict[tuple(combo_markers)] = [\n",
    "                tuple(stain_complete_df.index[i] for i in comb),\n",
    "                (),\n",
    "                (),\n",
    "                len(combo_labels),\n",
    "                tuple(combo_labels),\n",
    "                tuple(nuc_positions[i-1] for i in combo_labels) if len(combo_labels)>0 else (),\n",
    "                tuple(cyto_positions[i-1] for i in combo_labels) if len(combo_labels)>0 else (),\n",
    "                tuple(nuc_sizes[i-1] for i in combo_labels) if len(combo_labels)>0 else (),\n",
    "                tuple(cyto_sizes[i-1] for i in combo_labels) if len(combo_labels)>0 else (),\n",
    "                (),\n",
    "                (),\n",
    "                (),\n",
    "                (),\n",
    "                (),\n",
    "                (),\n",
    "                (),\n",
    "                (),\n",
    "                ()\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc27794-fce2-4632-80a0-56de4ea09181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for quantification results and truncate long values for display\n",
    "labels_df = pd.DataFrame.from_dict(labels_dict, orient='index', columns=['Condition', 'Laser', 'Color', 'Number', 'Shared labels', 'Mean nuclei positions [um]', 'Mean cytoplasm positions [um]', 'Nuclei size [um3]', 'Cytoplasm size [um3]', 'Marker size [um3]', 'Avg. marker intensity', 'STD marker intensity', 'Marker size cytoplasm [um3]', 'Avg. marker intensity cytoplasm', 'STD marker intensity cytoplasm', 'Marker size PCM [um3]', 'Avg. marker intensity PCM', 'STD marker intensity PCM'])\n",
    "labels_df.index.name = 'Combination'\n",
    "truncated_df = labels_df.copy()\n",
    "for col in [\"Shared labels\", \"Mean nuclei positions [um]\", \"Mean cytoplasm positions [um]\", \"Nuclei size [um3]\", \"Cytoplasm size [um3]\", 'Marker size [um3]', 'Avg. marker intensity', 'STD marker intensity', 'Marker size cytoplasm [um3]', 'Avg. marker intensity cytoplasm', 'STD marker intensity cytoplasm', 'Marker size PCM [um3]', 'Avg. marker intensity PCM', 'STD marker intensity PCM']:\n",
    "    truncated_df[col] = truncated_df[col].apply(lambda x: truncate_cell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb236ce0-4e76-4b10-8bf4-47351900c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display quantification DataFrame\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccdf1a-3cf6-4d83-b8a6-91abbc8cf81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics for nuclei and cell populations\n",
    "print('TOT CELLS =', labels_df['Number'][stain_complete_df['Marker']['NUCLEI']])\n",
    "print(\" \")\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (labels_df['Condition'][i] != 'NUCLEI + CYTOPLASM'):\n",
    "        print(f\" PERC {labels_df['Condition'][i]} ({marker}) = {100.0 * labels_df['Number'][i] / labels_df['Number'][0]} %\")\n",
    "print('_' * 80)\n",
    "print('MEAN SIZE NUCLEI =', np.mean(labels_df['Nuclei size [um3]'][stain_complete_df['Marker']['NUCLEI']]), 'um3')\n",
    "if 'CYTOPLASM' in stain_df.index:\n",
    "    print('MEAN SIZE CYTOPLASM =', np.mean(labels_df['Cytoplasm size [um3]'][stain_complete_df['Marker']['CYTOPLASM']]), 'um3')\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (labels_df['Condition'][i] != 'NUCLEI + CYTOPLASM'):\n",
    "        print(\" \")\n",
    "        print(f\" MEAN SIZE NUCLEI {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Nuclei size [um3]'][i])} um3\")\n",
    "        if 'CYTOPLASM' in stain_df.index:\n",
    "            print(f\" MEAN SIZE CYTOPLASM {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Cytoplasm size [um3]'][i])} um3\")\n",
    "print('_' * 80)\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Marker size [um3]'][i]!=()):\n",
    "        print(f\"MEAN SIZE {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Marker size [um3]'][i])} um3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f76a8-d1b6-45ad-9f4d-a358b2a1050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_full_dict = {}\n",
    "\n",
    "r_xyz = (r_X, r_Y, r_Z)\n",
    "zooms = zoom_factors\n",
    "nuc_positions, nuc_sizes, cyto_positions, cyto_sizes = compute_nuclei_cytoplasm_stats(im_segmentation_stack, r_xyz, zooms)\n",
    "\n",
    "c_nuc = None\n",
    "c_cyto = None\n",
    "\n",
    "if 'NUCLEI' in stain_complete_df.index:\n",
    "    c_nuc = stain_complete_df.index.get_loc('NUCLEI')\n",
    "if 'CYTOPLASM' in stain_complete_df.index:\n",
    "    c_cyto = stain_complete_df.index.get_loc('CYTOPLASM')\n",
    "\n",
    "if c_nuc is not None:\n",
    "    nuc_marker = stain_complete_df['Marker'][c_nuc]\n",
    "    labels_full_dict[nuc_marker] = [\n",
    "        stain_complete_df.index[c_nuc],\n",
    "        stain_complete_df['Laser'][c_nuc],\n",
    "        stain_complete_df['Color'][c_nuc],\n",
    "        int(np.max(im_segmentation_stack['Nuclei'])),\n",
    "        (),  # Shared labels placeholder\n",
    "        tuple(nuc_positions),\n",
    "        (),\n",
    "        tuple(nuc_sizes),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        ()\n",
    "    ]\n",
    "\n",
    "if c_cyto is not None:\n",
    "    cyto_marker = stain_complete_df['Marker'][c_cyto]\n",
    "    labels_full_dict[cyto_marker] = [\n",
    "        stain_complete_df.index[c_cyto],\n",
    "        stain_complete_df['Laser'][c_cyto],\n",
    "        stain_complete_df['Color'][c_cyto],\n",
    "        int(np.max(im_segmentation_stack['Cytoplasm'])),\n",
    "        (),\n",
    "        (),\n",
    "        tuple(cyto_positions),\n",
    "        (),\n",
    "        tuple(cyto_sizes),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        ()\n",
    "    ]\n",
    "\n",
    "filtered_img = im_final_stack['Filtered image']\n",
    "num_channels = filtered_img.shape[3]\n",
    "\n",
    "for c in range(num_channels):\n",
    "    condition = stain_complete_df.index[c]\n",
    "    if condition in ['NUCLEI', 'CYTOPLASM', 'PCM']:\n",
    "        continue\n",
    "    marker = stain_complete_df['Marker'][c]\n",
    "\n",
    "    full_labels, m_full_sizes, m_full_avg, m_full_std, m_full_cyto_sizes, m_full_cyto_avg, m_full_cyto_std, m_full_pcm_sizes, m_full_pcm_avg, m_full_pcm_std = compute_full_marker_stats_for_marker(c, im_final_stack, im_segmentation_stack, filtered_img, r_xyz, zooms)\n",
    "\n",
    "    labels_full_dict[marker] = [\n",
    "        condition,\n",
    "        stain_complete_df['Laser'][c],\n",
    "        stain_complete_df['Color'][c],\n",
    "        len(full_labels),\n",
    "        tuple(sorted(full_labels)),\n",
    "        tuple(nuc_positions[i-1] for i in full_labels) if len(full_labels)>0 else (),\n",
    "        tuple(cyto_positions[i-1] for i in full_labels) if len(full_labels)>0 else (),\n",
    "        tuple(nuc_sizes[i-1] for i in full_labels) if len(full_labels)>0 else (),\n",
    "        tuple(cyto_sizes[i-1] for i in full_labels) if len(full_labels)>0 else (),\n",
    "        tuple(m_full_sizes),\n",
    "        tuple(m_full_avg),\n",
    "        tuple(m_full_std),\n",
    "        tuple(m_full_cyto_sizes),\n",
    "        tuple(m_full_cyto_avg),\n",
    "        tuple(m_full_cyto_std),\n",
    "        tuple(m_full_pcm_sizes),\n",
    "        tuple(m_full_pcm_avg),\n",
    "        tuple(m_full_pcm_std)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774683e-67e9-41fd-aeac-c3567420cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for quantification results and truncate long values for display\n",
    "labels_full_df = pd.DataFrame.from_dict(labels_full_dict, orient='index', columns=['Condition', 'Laser', 'Color', 'Number', 'Shared labels', 'Mean nuclei positions [um]', 'Mean cytoplasm positions [um]', 'Nuclei size [um3]', 'Cytoplasm size [um3]', 'Marker size [um3]', 'Avg. marker intensity', 'STD marker intensity', 'Marker size cytoplasm [um3]', 'Avg. marker intensity cytoplasm', 'STD marker intensity cytoplasm', 'Marker size PCM [um3]', 'Avg. marker intensity PCM', 'STD marker intensity PCM'])\n",
    "labels_full_df.index.name = 'Combination'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4619e43-cc0a-4f33-8a4f-4553ed966270",
   "metadata": {},
   "source": [
    "### HISTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b190b0c-d7f6-42e1-9a01-f482d6268a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data = {}\n",
    "# Store original intensity ranges for PDF output\n",
    "intensity_ranges = {}\n",
    "\n",
    "for c in range(im_in.shape[3]):\n",
    "    if stain_df.index[c] != 'NUCLEI':\n",
    "\n",
    "        idx = c\n",
    "        seg_stack = im_segmentation_stack\n",
    "        seg_final = im_final_stack\n",
    "        \n",
    "        condition = stain_complete_df.index[idx]\n",
    "        marker_name = stain_complete_df['Marker'][idx]\n",
    "\n",
    "        seg_key = stain_df.index[idx]\n",
    "        marker_img = seg_final['Filtered image'][:,:,:,idx]\n",
    "        \n",
    "        max_n = int(np.max(seg_stack['Nuclei']))\n",
    "\n",
    "        # Find channel index in filtered_img\n",
    "        ch_idx = None\n",
    "        for i, cond in enumerate(stain_complete_df.index):\n",
    "            if cond == condition:\n",
    "                ch_idx = i\n",
    "                break\n",
    "\n",
    "        # Store original min/max from filtered image for this channel\n",
    "        if ch_idx is not None:\n",
    "            intensity_ranges[condition] = (\n",
    "                float(filtered_img[:, :, :, ch_idx].min()),\n",
    "                float(filtered_img[:, :, :, ch_idx].max())\n",
    "            )\n",
    "\n",
    "        for n in range(1, max_n + 1):\n",
    "\n",
    "            if n not in hist_data:\n",
    "                hist_data[n] = {}  # add nucleus\n",
    "            if condition not in hist_data[n]:\n",
    "                hist_data[n][condition] = []  # add condition for that nucleus\n",
    "\n",
    "            nuc_mask = (seg_stack['Nuclei'] == n)\n",
    "            cyto_mask = (seg_stack['Cytoplasm'] == n)\n",
    "            PCM_mask = (seg_stack['PCM'] == n)\n",
    "            # Marker presence in the nucleus/cell region\n",
    "            mask_marker_in_nucleus = (marker_img > 0) & ((nuc_mask+cyto_mask+PCM_mask) > 0)\n",
    "\n",
    "            if np.any(mask_marker_in_nucleus):\n",
    "                vox = np.where(mask_marker_in_nucleus)\n",
    "                if ch_idx is not None:\n",
    "                    vals = filtered_img[vox[0], vox[1], vox[2], ch_idx]\n",
    "                    if vals.size > 0:\n",
    "                        hist_data[n][condition].extend(vals.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c1a3e-a62e-4a16-9ac9-5bf8f2e177b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- REQUIRE: hist_data must exist in the form hist_data[n][condition] = list(values) ---\n",
    "# e.g. hist_data = {1: {'MACRO': [...], 'CD3': [...], 'CD20': [...]}, 2: {...}, ...}\n",
    "\n",
    "# Derive nuclei and condition list from hist_data\n",
    "nuclei = sorted(hist_data.keys())\n",
    "if len(nuclei) == 0:\n",
    "    raise ValueError(\"hist_data is empty. Fill hist_data before plotting.\")\n",
    "\n",
    "max_n = max(nuclei)\n",
    "all_conditions = sorted({cond for ndata in hist_data.values() for cond in ndata.keys()})\n",
    "\n",
    "# Assign consistent colors per condition\n",
    "color_cycle = plt.cm.tab10\n",
    "condition_colors = {cond: color_cycle(i % 10) for i, cond in enumerate(all_conditions)}\n",
    "\n",
    "# Limit figure size to prevent matplotlib rendering errors\n",
    "max_subplots = min(max_n, 20)  # Cap at 20 subplots\n",
    "height = min(3 * max_subplots, 60)  # Cap height at 60 inches\n",
    "\n",
    "# Prepare multi-row figure (one subplot per nucleus)\n",
    "fig, axes = plt.subplots(max_subplots, 1, figsize=(10, height), sharex=True)\n",
    "if max_subplots == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "x_grid = np.linspace(0, 255, 400)\n",
    "\n",
    "# Only plot nuclei that fit in the subplot grid\n",
    "nuclei_to_plot = nuclei[:max_subplots]\n",
    "\n",
    "for idx, n in enumerate(nuclei_to_plot):\n",
    "    ax = axes[idx]  # Use subplot index instead of nucleus number\n",
    "    ax.set_title(f\"Nucleus {n}\")\n",
    "    ax.set_xlim(0, 255)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.grid(alpha=0.2)\n",
    "\n",
    "    # For each condition, plot density if data exists\n",
    "    for cond in all_conditions:\n",
    "        vals = np.array(hist_data.get(n, {}).get(cond, []))\n",
    "        if stain_complete_df['Color'][cond] != 'WHITE':\n",
    "            color = stain_complete_df['Color'][cond]  \n",
    "        else:\n",
    "            color = 'GRAY'\n",
    "\n",
    "        if vals.size == 0:\n",
    "            # no data for this nucleus & condition: skip curve plotting\n",
    "            continue\n",
    "\n",
    "        # try KDE, fallback if singular\n",
    "        y_grid = None\n",
    "        try:\n",
    "            kde = gaussian_kde(vals)\n",
    "            y_grid = kde(x_grid)\n",
    "        except Exception:\n",
    "            # fallback: create a narrow Gaussian around the mean (handles zero-variance)\n",
    "            mean_val = vals.mean()\n",
    "            bw = 1.0  # small bandwidth fallback\n",
    "            y_grid = np.exp(-0.5 * ((x_grid - mean_val) / bw) ** 2)\n",
    "        \n",
    "        # normalize y to 0-1\n",
    "        if y_grid.max() > 0:\n",
    "            y_norm = y_grid / y_grid.max()\n",
    "        else:\n",
    "            y_norm = y_grid\n",
    "\n",
    "        # plot density curve\n",
    "        ax.plot(x_grid, y_norm, linewidth=2, color=color)\n",
    "\n",
    "        # compute mean and std from raw vals\n",
    "        mean_val = float(vals.mean())\n",
    "        std_val = float(vals.std())\n",
    "\n",
    "        # vertical mean line (same color)\n",
    "        ax.axvline(mean_val, linestyle='--', linewidth=1.5, color=color)\n",
    "\n",
    "        # y position for std-line: read normalized KDE at mean (interpolate)\n",
    "        y_at_mean = np.interp(mean_val, x_grid, y_norm)\n",
    "\n",
    "        # horizontal std line from mean-std to mean+std (clamped to axis)\n",
    "        x_start = max(0.0, mean_val - std_val)\n",
    "        x_end = min(255.0, mean_val + std_val)\n",
    "        ax.hlines(y_at_mean, x_start, x_end, linewidth=2, color=color)\n",
    "\n",
    "    # Build a legend showing all conditions with their assigned color (consistent across plots)\n",
    "    legend_handles = [Line2D([0], [0], color=stain_complete_df['Color'][c] if stain_complete_df['Color'][c] != 'WHITE' else 'GRAY', lw=2) for c in all_conditions]\n",
    "    ax.legend(legend_handles, all_conditions, loc='upper right', framealpha=0.9)\n",
    "\n",
    "    if n == nuclei_to_plot[-1]:\n",
    "        ax.set_xlabel(\"Intensity (0–255)\")\n",
    "\n",
    "axes[0].set_ylabel(\"Relative Density (0–1)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a7e7c-45eb-4e7a-9217-cf91bb305d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full block: one nucleus per page, 3 channel crops + merged in one horizontal row\n",
    "styles = getSampleStyleSheet()\n",
    "\n",
    "create_row_pdf(\n",
    "    output_pdf=Path(input_file).stem + \"_nuclei_marker.pdf\",\n",
    "    pad=20,\n",
    "    thumb_size=(2.0 * inch, 2.0 * inch)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333a47d-9919-4bfe-ae8b-41706aec1673",
   "metadata": {},
   "source": [
    "## Evaluate cell distribution in the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35bbdd-693f-45c5-8654-fd6c387a19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial distribution of nuclei and cells\n",
    "im_in=im_final_stack['Filtered image']\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 15))\n",
    "for i, marker in enumerate(labels_df.index):   \n",
    "    xcoor = [t[0] for t in labels_df['Mean cytoplasm positions [um]'][i]]\n",
    "    ycoor = [t[1] for t in labels_df['Mean cytoplasm positions [um]'][i]]\n",
    "    zcoor = [t[2] for t in labels_df['Mean cytoplasm positions [um]'][i]] \n",
    "    xcount, xbins = np.histogram(xcoor, range=(0, im_in.shape[2] * r_X /zoom_factors[2]), bins=30)\n",
    "    ycount, ybins = np.histogram(ycoor, range=(0, im_in.shape[1] * r_Y /zoom_factors[1]), bins=30)\n",
    "    zcount, zbins = np.histogram(zcoor, range=(0, im_in.shape[0] * r_Z /zoom_factors[0]), bins=30)\n",
    "    xbin_centers = (xbins[:-1] + xbins[1:]) / 2\n",
    "    ybin_centers = (ybins[:-1] + ybins[1:]) / 2\n",
    "    zbin_centers = (zbins[:-1] + zbins[1:]) / 2\n",
    "    if (np.size(marker)==1):\n",
    "        color = stain_complete_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "        if color == '':\n",
    "            color='BLUE'\n",
    "        if (labels_df['Condition'][i]!='NUCLEI'):\n",
    "            axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),color=color)\n",
    "            axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),color=color)\n",
    "            axs[2].plot(zbin_centers,zcount,label=str(labels_df['Condition'][i]),color=color)\n",
    "    else:\n",
    "        rgb_list=[]\n",
    "        for k in range(np.size(marker)):\n",
    "            if stain_df.loc[(labels_df['Condition'][i][k])]['Color']!='WHITE':\n",
    "                rgb_list.append(stain_complete_df.loc[(labels_df['Condition'][i][k])]['Color'])\n",
    "            else:\n",
    "                rgb_list.append('GRAY')\n",
    "\n",
    "        colors_rgb = [to_rgb(name) for name in rgb_list]\n",
    "\n",
    "        r_total, g_total, b_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for r, g, b in colors_rgb:\n",
    "            r_total += r\n",
    "            g_total += g\n",
    "            b_total += b\n",
    "        \n",
    "        r_final = min(r_total, 1.0)\n",
    "        g_final = min(g_total, 1.0)\n",
    "        b_final = min(b_total, 1.0)\n",
    "    \n",
    "        final_rgb = (r_final, g_final, b_final)\n",
    "        \n",
    "        axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        axs[2].plot(zbin_centers,zcount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        \n",
    "axs[0].set_title('NUCLEI X DISTRIBUTION')\n",
    "axs[0].set_xlabel('[μm]')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[0].set_facecolor('black')\n",
    "axs[1].set_title('NUCLEI Y DISTRIBUTION')\n",
    "axs[1].set_xlabel('[μm]')\n",
    "axs[1].legend(loc='upper right')\n",
    "axs[1].set_facecolor('black')\n",
    "axs[2].set_title('NUCLEI Z DISTRIBUTION')\n",
    "axs[2].set_xlabel('[μm]')\n",
    "axs[2].legend(loc='upper right')\n",
    "axs[2].set_facecolor('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d02b15-c10b-4b95-8882-ff6769eadbdb",
   "metadata": {},
   "source": [
    "## Evaluate cell size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02a90b-0bb0-46f7-875d-e438714bc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot size distribution of nuclei and cells\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 10))\n",
    "nuclei_max_size = max(x for t in labels_df['Nuclei size [um3]'] for x in t)\n",
    "cytoplasm_max_size = max(x for t in labels_df['Cytoplasm size [um3]'] for x in t)\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    nuclei_sizes = list(labels_df['Nuclei size [um3]'][i])\n",
    "    cell_sizes = list(labels_df['Cytoplasm size [um3]'][i])\n",
    "    if np.size(marker)==1:\n",
    "        if stain_complete_df.loc[(labels_df['Condition'][i])]['Color']=='':\n",
    "            color = 'BLUE'\n",
    "        else:\n",
    "            if stain_complete_df.loc[(labels_df['Condition'][i])]['Color']!='WHITE':\n",
    "                color = stain_complete_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "            else:\n",
    "                color = 'GRAY'\n",
    "        #color = stain_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "        #axs[0].hist(nuclei_sizes, range=(0, nuclei_max_size), bins=30, label=str(labels_df['Condition'][i]), alpha=1/len(labels_df), color=color)\n",
    "    else:\n",
    "        rgb_list=[]\n",
    "        for k in range(np.size(marker)):\n",
    "            if stain_df.loc[(labels_df['Condition'][i][k])]['Color']!='WHITE':\n",
    "                rgb_list.append(stain_complete_df.loc[(labels_df['Condition'][i][k])]['Color'])\n",
    "            else:\n",
    "                rgb_list.append('GRAY')\n",
    "\n",
    "        colors_rgb = [to_rgb(name) for name in rgb_list]\n",
    "\n",
    "        r_total, g_total, b_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for r, g, b in colors_rgb:\n",
    "            r_total += r\n",
    "            g_total += g\n",
    "            b_total += b\n",
    "        \n",
    "        r_final = min(r_total, 1.0)\n",
    "        g_final = min(g_total, 1.0)\n",
    "        b_final = min(b_total, 1.0)\n",
    "    \n",
    "        color = (r_final, g_final, b_final)\n",
    "        \n",
    "    if labels_df['Condition'][i] != 'CYTOPLASM':    \n",
    "        axs[0].hist(nuclei_sizes, range=(0, nuclei_max_size), bins=30, label=str(labels_df['Condition'][i]), alpha=1/len(labels_df), color=color)\n",
    "    if labels_df['Condition'][i] != 'NUCLEI':\n",
    "        axs[1].hist(cell_sizes, range=(0, cytoplasm_max_size), bins=30, label=str(labels_df['Condition'][i]), alpha=1/(len(labels_df)-1), color=color)\n",
    "axs[0].set_title('NUCLEI SIZE DISTRIBUTION')\n",
    "axs[0].set_xlabel('[μm3]')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[1].set_title('CELL SIZE DISTRIBUTION')\n",
    "axs[1].set_xlabel('[μm3]')\n",
    "axs[1].legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c710e23-4fc2-4dbe-8999-298bcff0190d",
   "metadata": {},
   "source": [
    "## CREATE .VTK VOLUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6af6f0-3b6b-4514-bfc4-6f1c925af8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond = ndi.generate_binary_structure(rank=3, connectivity=1)\n",
    "blocks_nuclei=pv.MultiBlock()\n",
    "blocks_cyto=pv.MultiBlock()\n",
    "blocks_PCM=pv.MultiBlock()\n",
    "nuclei_stl_old=mr.Mesh()\n",
    "cyto_stl_old=mr.Mesh()\n",
    "PCM_stl_old=mr.Mesh()\n",
    "\n",
    "nuc_vol=np.zeros((np.max(im_segmentation_stack['Nuclei'])+1,))\n",
    "nuc_coord=np.zeros((np.max(im_segmentation_stack['Nuclei'])+1,3))\n",
    "nuc_list=np.zeros((np.max(im_segmentation_stack['Nuclei'])+1,))\n",
    "\n",
    "cyto_vol=np.zeros((np.max(im_segmentation_stack['Cytoplasm'])+1,))\n",
    "cyto_coord=np.zeros((np.max(im_segmentation_stack['Cytoplasm'])+1,3))\n",
    "cyto_list=np.zeros((np.max(im_segmentation_stack['Cytoplasm'])+1,))\n",
    "\n",
    "PCM_vol=np.zeros((np.max(im_segmentation_stack['PCM'])+1,))\n",
    "PCM_coord=np.zeros((np.max(im_segmentation_stack['PCM'])+1,3))\n",
    "PCM_list=np.zeros((np.max(im_segmentation_stack['PCM'])+1,))\n",
    "\n",
    "#agg_id=1\n",
    "\n",
    "k=0\n",
    "for j in range(1,np.max(im_segmentation_stack['Nuclei'])+1):\n",
    "    clear_output(wait=True)\n",
    "    print('NUCLEI ' + str(j) + ' / ' + str(np.max(im_segmentation_stack['Nuclei'])))\n",
    "    \n",
    "    simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['Nuclei']==j))\n",
    "    floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "    mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "    mr.saveMesh(mesh_stl, \"part_nuclei_mesh.stl\" )\n",
    "    \n",
    "    mesh_nuclei = pv.read(\"part_nuclei_mesh.stl\")\n",
    "    if mesh_nuclei.volume>0.0:\n",
    "        mesh_nuclei.decimate(target_reduction=0.8, inplace=True)\n",
    "\n",
    "        nuc_vol[k]=mesh_nuclei.volume\n",
    "        nuc_coord[k]=mesh_nuclei.center\n",
    "        nuc_list[k]=j\n",
    "\n",
    "        mesh_nuclei.cell_data['ID']=np.ones(mesh_nuclei.n_cells)*(k+1)\n",
    "        mesh_nuclei.cell_data['Nuclei volume (um3)']=np.ones(mesh_nuclei.n_cells)*nuc_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)\n",
    "        mesh_nuclei.cell_data['Z nuclei (um)']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][0] * r_Z /zoom_factors[0]\n",
    "        mesh_nuclei.cell_data['Y nuclei (um)']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][1] * r_Y /zoom_factors[1]\n",
    "        mesh_nuclei.cell_data['X nuclei (um)']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][2] * r_X /zoom_factors[2]\n",
    "        \n",
    "        blocks_nuclei.append(mesh_nuclei)\n",
    "        k=k+1\n",
    "\n",
    "\n",
    "    simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['Cytoplasm']==j))\n",
    "    floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "    mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "    mr.saveMesh(mesh_stl, \"part_cyto_mesh.stl\" )\n",
    "    \n",
    "    mesh_cyto = pv.read(\"part_cyto_mesh.stl\")\n",
    "\n",
    "    simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['PCM']==j))\n",
    "    floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "    mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "    mr.saveMesh(mesh_stl, \"part_PCM_mesh.stl\" )\n",
    "    \n",
    "    mesh_PCM = pv.read(\"part_PCM_mesh.stl\")\n",
    "    \n",
    "    if mesh_cyto.volume>0.0:\n",
    "        mesh_cyto.decimate(target_reduction=0.8, inplace=True)\n",
    "        mesh_PCM.decimate(target_reduction=0.8, inplace=True)\n",
    "\n",
    "        cyto_vol[k]=mesh_cyto.volume\n",
    "        cyto_coord[k]=mesh_cyto.center\n",
    "        cyto_list[k]=j\n",
    "\n",
    "        PCM_vol[k]=mesh_PCM.volume\n",
    "        PCM_coord[k]=mesh_PCM.center\n",
    "        PCM_list[k]=j\n",
    "\n",
    "        mesh_cyto.cell_data['ID']=np.ones(mesh_cyto.n_cells)*(k+1)\n",
    "        mesh_PCM.cell_data['ID']=np.ones(mesh_PCM.n_cells)*(k+1)\n",
    "        mesh_cyto.cell_data['Cellular volume (um3)']=np.ones(mesh_cyto.n_cells)*cyto_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)\n",
    "        mesh_PCM.cell_data['PCM volume (um3)']=np.ones(mesh_PCM.n_cells)*PCM_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)\n",
    "        mesh_cyto.cell_data['Z cell (um)']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][0] * r_Z /zoom_factors[0]\n",
    "        mesh_cyto.cell_data['Y cell (um)']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][1] * r_Y /zoom_factors[1]\n",
    "        mesh_cyto.cell_data['X cell (um)']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][2] * r_X /zoom_factors[2]\n",
    "        mesh_PCM.cell_data['Z PCM (um)']=np.ones(mesh_PCM.n_cells)*PCM_coord[k][0] * r_Z /zoom_factors[0]\n",
    "        mesh_PCM.cell_data['Y PCM (um)']=np.ones(mesh_PCM.n_cells)*PCM_coord[k][1] * r_Y /zoom_factors[1]\n",
    "        mesh_PCM.cell_data['X PCM (um)']=np.ones(mesh_PCM.n_cells)*PCM_coord[k][2] * r_X /zoom_factors[2]\n",
    "        for i, marker in enumerate(labels_full_df.index):\n",
    "            if (labels_full_df['Condition'][i]!='NUCLEI') & (labels_full_df['Condition'][i]!='CYTOPLASM') & (np.size(marker)==1):\n",
    "                if j in list(labels_full_df['Shared labels'][i]):\n",
    "                    mesh_cyto.cell_data[marker+' volume (um3)']=np.ones(mesh_cyto.n_cells)*(labels_full_df['Marker size [um3]'][i][list(labels_full_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_PCM.cell_data[marker+' volume (um3)']=np.ones(mesh_PCM.n_cells)*(labels_full_df['Marker size [um3]'][i][list(labels_full_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_cyto.cell_data[marker+' volume cytoplasm (um3)']=np.ones(mesh_cyto.n_cells)*(labels_full_df['Marker size cytoplasm [um3]'][i][list(labels_full_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_PCM.cell_data[marker+' volume PCM (um3)']=np.ones(mesh_PCM.n_cells)*(labels_full_df['Marker size PCM [um3]'][i][list(labels_full_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_cyto.cell_data[marker+' rel. vol. (-)']=np.ones(mesh_cyto.n_cells)*((labels_full_df['Marker size [um3]'][i][list(labels_full_df['Shared labels'][i]).index(j)])/((cyto_vol[k]+PCM_vol[k]) * r_X * r_Y * r_Z / np.prod(zoom_factors)))\n",
    "                    mesh_PCM.cell_data[marker+' rel. vol. (-)']=np.ones(mesh_PCM.n_cells)*((labels_full_df['Marker size [um3]'][i][list(labels_full_df['Shared labels'][i]).index(j)])/((cyto_vol[k]+PCM_vol[k]) * r_X * r_Y * r_Z / np.prod(zoom_factors)))\n",
    "                    mesh_cyto.cell_data[marker+' rel. vol. cytoplasm (-)']=np.ones(mesh_cyto.n_cells)*((labels_full_df['Marker size cytoplasm [um3]'][i][list(labels_full_df['Shared labels'][i]).index(j)])/(cyto_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)))\n",
    "                    mesh_PCM.cell_data[marker+' rel. vol. PCM (-)']=np.ones(mesh_PCM.n_cells)*((labels_full_df['Marker size PCM [um3]'][i][list(labels_full_df['Shared labels'][i]).index(j)])/(PCM_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)))\n",
    "                    mesh_cyto.cell_data[marker+' avg. intensity (-)']=np.ones(mesh_cyto.n_cells)*(labels_full_df['Avg. marker intensity'][i][list(labels_full_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_PCM.cell_data[marker+' avg. intensity (-)']=np.ones(mesh_PCM.n_cells)*(labels_full_df['Avg. marker intensity'][i][list(labels_full_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_cyto.cell_data[marker+' avg. cytoplasm int. (-)']=np.ones(mesh_cyto.n_cells)*(labels_full_df['Avg. marker intensity cytoplasm'][i][list(labels_full_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_PCM.cell_data[marker+' avg. PCM int. (-)']=np.ones(mesh_PCM.n_cells)*(labels_full_df['Avg. marker intensity PCM'][i][list(labels_full_df['Shared labels'][i]).index(j)])\n",
    "                else:\n",
    "                    mesh_cyto.cell_data[marker+' expression (um3)']=np.ones(mesh_cyto.n_cells)*(0.0)\n",
    "                    mesh_cyto.cell_data[marker+' rel. expr. (-)']=np.ones(mesh_cyto.n_cells)*(0.0)\n",
    "                # ass_channel_2=globals()[channel+'mag']*(NUCLEIlab==val)/np.max(globals()[channel+'mag'])\n",
    "                # mesh_cyto.cell_data[channel+'_perc_rel']=np.ones(mesh_nuclei.n_cells)*(np.sum(ass_channel_2)/np.sum(NUCLEIlab==val))\n",
    "        \n",
    "        blocks_cyto.append(mesh_cyto)\n",
    "        blocks_PCM.append(mesh_PCM)\n",
    "        #k=k+1\n",
    "\n",
    "    #j=j-1\n",
    "\n",
    "# nuc_vol=nuc_vol[0:k-1]\n",
    "# nuc_coord=nuc_coord[0:k-1]\n",
    "# nuc_list=nuc_list[0:k-1]\n",
    "blocks_nuclei.extract_geometry().save(Path(input_file).stem+'_NUCLEI_labelled.vtk')\n",
    "blocks_cyto.extract_geometry().save(Path(input_file).stem+'_CYTOPLASM_labelled.vtk')\n",
    "blocks_PCM.extract_geometry().save(Path(input_file).stem+'_PCM_labelled.vtk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2bcca6-f1df-432c-b916-278fe84b44de",
   "metadata": {},
   "source": [
    "## and .STL for markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966a994-8ef8-4b37-af9b-74a8e21452d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, marker in enumerate(stain_complete_df.index):\n",
    "    if (stain_complete_df.index[c] != 'NUCLEI') & (stain_complete_df.index[c] != 'CYTOPLASM') & (stain_complete_df.index[c] != 'PCM'):\n",
    "        simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack[stain_df.index[c]]>0))\n",
    "        floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "        mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "        mr.saveMesh(mesh_stl,Path(input_file).stem + \"_\" + stain_complete_df['Marker'][c] + \"_mesh.stl\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070bde8-0355-4bec-a563-1f7740d942a2",
   "metadata": {},
   "source": [
    "### Create a complete report XSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4282f-7756-4c49-8a50-fb7d69eb4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export quantification results to Excel file\n",
    "with pd.ExcelWriter(Path(input_file).stem + '_segmentation.xlsx', engine='xlsxwriter') as writer:\n",
    "    original_stain_complete_df.to_excel(writer, sheet_name='Staining', index=True)\n",
    "    xlsx_dict = {}\n",
    "    columns = ['X position [um]', 'Y position [um]', 'Z position [um]', 'Nuclei size [um3]']\n",
    "    # for i, marker in enumerate(labels_full_df.index):\n",
    "    #     if (labels_full_df['Condition'][i] != 'NUCLEI') & (labels_full_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_full_df['Condition'][i])==1):\n",
    "    #         columns.append(f\"{marker} ({labels_full_df['Condition'][i]})\")\n",
    "    #         columns.append(f\"{labels_full_df['Condition'][i]} marker size [um3]\")\n",
    "    for k in range(1, int(labels_full_df['Number'][0])):\n",
    "        row = [labels_full_df['Mean nuclei positions [um]'][0][k-1], labels_full_df['Nuclei size [um3]'][0][k-1]]\n",
    "        row = [row[0][0], row[0][1], row[0][2], row[1]]\n",
    "        # for i, marker in enumerate(labels_full_df.index):\n",
    "        #     if (labels_full_df['Condition'][i] != 'NUCLEI') & (labels_full_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_full_df['Condition'][i])==1):\n",
    "        #         shared = labels_full_df['Shared labels'][i]\n",
    "        #         if k in shared:\n",
    "        #             idx = list(shared).index(k)\n",
    "        #             #row.append(marker)\n",
    "        #             row.append(labels_full_df['Marker size [um3]'][marker][idx])\n",
    "        #         else:\n",
    "        #             row.extend(['', ''])\n",
    "        xlsx_dict[k] = row\n",
    "    cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=columns)\n",
    "    cell_df.to_excel(writer, sheet_name='NUCLEI', index=True)  \n",
    "    xlsx_dict = {}\n",
    "    columns = ['X position [um]', 'Y position [um]', 'Z position [um]', 'Cytoplasm size [um3]']  \n",
    "    for i, marker in enumerate(labels_full_df.index):\n",
    "        if (labels_full_df['Condition'][i] != 'NUCLEI') & (labels_full_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_full_df['Condition'][i])==1):\n",
    "            #columns.append(f\"{marker} ({labels_full_df['Condition'][i]})\")\n",
    "            columns.append(f\"{labels_full_df.index[i]} marker size [um3]\")\n",
    "            columns.append(f\"{labels_full_df.index[i]} marker size cytoplasm [um3]\")\n",
    "            columns.append(f\"{labels_full_df.index[i]} marker size PCM [um3]\")\n",
    "            columns.append(f\"{labels_full_df.index[i]} intensity [-]\")\n",
    "            columns.append(f\"{labels_full_df.index[i]} STD\")\n",
    "            columns.append(f\"{labels_full_df.index[i]} intensity cytoplasm [-]\")\n",
    "            columns.append(f\"{labels_full_df.index[i]} STD\")\n",
    "            columns.append(f\"{labels_full_df.index[i]} intensity PCM [-]\")\n",
    "            columns.append(f\"{labels_full_df.index[i]} STD\")\n",
    "    for k in range(1, int(labels_full_df['Number'][0])):\n",
    "        row = [labels_full_df['Mean cytoplasm positions [um]'][1][k-1], labels_full_df['Cytoplasm size [um3]'][1][k-1]]\n",
    "        row = [row[0][0], row[0][1], row[0][2], row[1]]\n",
    "        for i, marker in enumerate(labels_full_df.index):\n",
    "            if (labels_full_df['Condition'][i] != 'NUCLEI') & (labels_full_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_full_df['Condition'][i])==1):\n",
    "                shared = labels_full_df['Shared labels'][i]\n",
    "                if k in shared:\n",
    "                    idx = list(shared).index(k)\n",
    "                    #row.append(marker)\n",
    "                    row.append(labels_full_df['Marker size [um3]'][marker][idx])\n",
    "                    row.append(labels_full_df['Marker size cytoplasm [um3]'][marker][idx])\n",
    "                    row.append(labels_full_df['Marker size PCM [um3]'][marker][idx])\n",
    "                    row.append(labels_full_df['Avg. marker intensity'][marker][idx])\n",
    "                    row.append(labels_full_df['STD marker intensity'][marker][idx])\n",
    "                    row.append(labels_full_df['Avg. marker intensity cytoplasm'][marker][idx])\n",
    "                    row.append(labels_full_df['STD marker intensity cytoplasm'][marker][idx])\n",
    "                    row.append(labels_full_df['Avg. marker intensity PCM'][marker][idx])\n",
    "                    row.append(labels_full_df['STD marker intensity PCM'][marker][idx])\n",
    "                else:\n",
    "                    row.extend([' ',' ',' ',' ',' ',' ',' ',' ',' '])\n",
    "        xlsx_dict[k] = row\n",
    "    cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=columns)\n",
    "    cell_df.to_excel(writer, sheet_name='CYTOPLASM', index=True)\n",
    "    resume_df = labels_full_df.drop(columns=['Shared labels', 'Mean nuclei positions [um]', 'Mean cytoplasm positions [um]', 'Nuclei size [um3]', 'Cytoplasm size [um3]', 'Marker size [um3]', 'Avg. marker intensity', 'Marker size cytoplasm [um3]', 'Avg. marker intensity cytoplasm', 'Marker size PCM [um3]', 'Avg. marker intensity PCM'])\n",
    "    resume_df['Laser'] = [\n",
    "        labels_full_df['Laser'][t] if (np.size(labels_full_df['Condition'][t])==1) else ''\n",
    "        for t in range(len(labels_full_df))\n",
    "    ]\n",
    "    resume_df['Color'] = [\n",
    "        labels_full_df['Color'][t] if (np.size(labels_full_df['Condition'][t])==1) else ''\n",
    "        for t in range(len(labels_full_df))\n",
    "    ]\n",
    "    resume_df['%'] = [\n",
    "        100.0 * labels_full_df['Number'][t] / labels_full_df['Number'][0] if labels_full_df['Condition'][t] != 'NUCLEI' else ''\n",
    "        for t in range(len(labels_full_df))\n",
    "    ]\n",
    "    resume_df['Mean nuclei size [um3]'] = [np.mean(t) for t in labels_full_df['Nuclei size [um3]']]\n",
    "    resume_df['Mean cytoplasm size [um3]'] = [np.mean(t) for t in labels_full_df['Cytoplasm size [um3]']]\n",
    "    resume_df['Mean marker size [um3]'] = [\n",
    "        np.mean(val) if (labels_full_df['Condition'][t] != 'NUCLEI') & (labels_full_df['Condition'][t] != 'CYTOPLASM') & (np.size(labels_full_df['Condition'][t])==1) else ''\n",
    "        for t, val in enumerate(labels_full_df['Marker size [um3]'])\n",
    "    ]\n",
    "    resume_df.to_excel(writer, sheet_name='RECAP', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bf51e-260b-4374-934c-24464188ef5d",
   "metadata": {},
   "source": [
    "# CREATE .inp FOR FINITE ELEMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136c70d-e8e3-48be-a6fe-609ed4e4ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['Nuclei']))\n",
    "floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)\n",
    "\n",
    "outVerts = mrn.getNumpyVerts(mesh_stl)\n",
    "#print(outVerts)\n",
    "\n",
    "outFaces = mrn.getNumpyFaces(mesh_stl.topology)\n",
    "\n",
    "tet = tetgen.TetGen(outVerts,outFaces)\n",
    "nodes,elems=tet.tetrahedralize(order=1, mindihedral=20, minratio=1.5)\n",
    "\n",
    "tet.write('FE_segmentation_full.vtk', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305c4d7-ade4-4f5e-b377-18ae57041db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshel = meshio.read('FE_segmentation_full.vtk')\n",
    "meshel.write('FE_segmentation.inp')\n",
    "\n",
    "for c in range(1, np.max(im_segmentation_stack['Nuclei'])+1):\n",
    "    globals()[str(c)+'cell_el']=[]\n",
    "\n",
    "for ce, x in enumerate(elems):\n",
    "    #print(np.shape(np.uint16(np.mean(nodes[x],0))))\n",
    "    coord=np.int16(np.round(np.mean(nodes[x],0),0))\n",
    "    step=0\n",
    "    taken=False\n",
    "    while not(taken):\n",
    "        step+=1\n",
    "        coord[coord<step]=1\n",
    "        for k in [0,1,2]:\n",
    "            if coord[k]>=np.shape(im_segmentation_stack['Nuclei'])[k]+1-step:coord[k]=np.shape(im_segmentation_stack['Nuclei'])[k]-1\n",
    "        elemlist=im_segmentation_stack['Nuclei'][coord[0]-step:coord[0]+1+step,coord[1]-step:coord[1]+1+step,coord[2]-step:coord[2]+1+step].flatten()\n",
    "        #print(elemlist)\n",
    "        if sum(elemlist)>0:\n",
    "            c_el=st.mode(elemlist[elemlist!=0])\n",
    "            taken=True\n",
    "\n",
    "    #print(c_el)\n",
    "    if c_el!=0:\n",
    "        globals()[str(c_el)+'cell_el'].append(ce+1)\n",
    "\n",
    "f = open(\"FE_segmentation.inp\", \"a\")\n",
    "for c in range(1,np.max(im_segmentation_stack['Nuclei'])+1):\n",
    "    f.write(\"*Elset, elset=cell\" + str(c) + \"\\n\")\n",
    "    j=1\n",
    "    for t in range(1, np.size(globals()[str(c)+'cell_el'])):\n",
    "        f.write(str(globals()[str(c)+'cell_el'][t]) + \",\")\n",
    "        j+=1\n",
    "        if j>16:\n",
    "            f.write(\"\\n\")\n",
    "            j=1\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513300b-4e15-4b54-bea3-b60a737b3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now insert *PART header manually\n",
    "with open(\"FE_segmentation.inp\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(Path(input_file).stem + \"_FEA.inp\", \"w\") as f:\n",
    "    for line in lines:\n",
    "        if (line==\"*NODE\\n\"):\n",
    "            f.write(\"*PART, name=Part-1\\n\")\n",
    "        f.write(line)\n",
    "    f.write(\"*END PART\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab0a4d-5051-4a2a-972b-7e3a1c3d8ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
